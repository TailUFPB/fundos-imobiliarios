{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Rankeamento_Modelo_FIIS.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM94VG8Uo/+U55JaFHuZjZZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TailUFPB/fundos-imobiliarios/blob/main/Rankeamento_Modelo_FIIS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9vHJX-Ol6Xi"
      },
      "source": [
        "# Rankeamento de fundos e modelo de classificação"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukvb0wL9qgHA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70d3ecbd-0cd2-452b-ffc1-8e0dfbb79ee5"
      },
      "source": [
        "#Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "!pip install pycaret\n",
        "from pycaret.classification import *\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import preprocessing"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pycaret\n",
            "  Downloading pycaret-2.3.2-py3-none-any.whl (263 kB)\n",
            "\u001b[?25l\r\u001b[K     |█▎                              | 10 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 20 kB 31.8 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 30 kB 16.4 MB/s eta 0:00:01\r\u001b[K     |█████                           | 40 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 51 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 61 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 71 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 81 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 92 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 102 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 112 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 122 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 133 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 143 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 153 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 163 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 174 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 184 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 194 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 204 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 215 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 225 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 235 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 245 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 256 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 263 kB 6.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pycaret) (1.0.1)\n",
            "Collecting yellowbrick>=1.0.1\n",
            "  Downloading yellowbrick-1.3.post1-py3-none-any.whl (271 kB)\n",
            "\u001b[K     |████████████████████████████████| 271 kB 49.5 MB/s \n",
            "\u001b[?25hCollecting Boruta\n",
            "  Downloading Boruta-0.3-py3-none-any.whl (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 3.2 MB/s \n",
            "\u001b[?25hCollecting pyod\n",
            "  Downloading pyod-0.9.0.tar.gz (105 kB)\n",
            "\u001b[K     |████████████████████████████████| 105 kB 45.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cufflinks>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from pycaret) (0.17.3)\n",
            "Collecting imbalanced-learn==0.7.0\n",
            "  Downloading imbalanced_learn-0.7.0-py3-none-any.whl (167 kB)\n",
            "\u001b[K     |████████████████████████████████| 167 kB 52.2 MB/s \n",
            "\u001b[?25hCollecting pandas-profiling>=2.8.0\n",
            "  Downloading pandas_profiling-3.0.0-py2.py3-none-any.whl (248 kB)\n",
            "\u001b[K     |████████████████████████████████| 248 kB 40.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: IPython in /usr/local/lib/python3.7/dist-packages (from pycaret) (5.5.0)\n",
            "Collecting scikit-learn==0.23.2\n",
            "  Downloading scikit_learn-0.23.2-cp37-cp37m-manylinux1_x86_64.whl (6.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 46.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy==1.19.5 in /usr/local/lib/python3.7/dist-packages (from pycaret) (1.19.5)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.7/dist-packages (from pycaret) (0.11.1)\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.7/dist-packages (from pycaret) (1.5.0)\n",
            "Requirement already satisfied: spacy<2.4.0 in /usr/local/lib/python3.7/dist-packages (from pycaret) (2.2.4)\n",
            "Requirement already satisfied: gensim<4.0.0 in /usr/local/lib/python3.7/dist-packages (from pycaret) (3.6.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from pycaret) (3.2.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from pycaret) (3.2.5)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.7/dist-packages (from pycaret) (0.15.3)\n",
            "Requirement already satisfied: plotly>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from pycaret) (4.4.1)\n",
            "Collecting pyLDAvis\n",
            "  Downloading pyLDAvis-3.3.1.tar.gz (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 25.1 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting kmodes>=0.10.1\n",
            "  Downloading kmodes-0.11.0-py2.py3-none-any.whl (18 kB)\n",
            "Collecting lightgbm>=2.3.1\n",
            "  Downloading lightgbm-3.2.1-py3-none-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.0 MB 24.0 MB/s \n",
            "\u001b[?25hCollecting umap-learn\n",
            "  Downloading umap-learn-0.5.1.tar.gz (80 kB)\n",
            "\u001b[K     |████████████████████████████████| 80 kB 8.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from pycaret) (7.6.3)\n",
            "Collecting mlxtend>=0.17.0\n",
            "  Downloading mlxtend-0.18.0-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 30.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from pycaret) (1.1.5)\n",
            "Requirement already satisfied: scipy<=1.5.4 in /usr/local/lib/python3.7/dist-packages (from pycaret) (1.4.1)\n",
            "Collecting mlflow\n",
            "  Downloading mlflow-1.19.0-py3-none-any.whl (14.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.4 MB 58 kB/s \n",
            "\u001b[?25hCollecting scikit-plot\n",
            "  Downloading scikit_plot-0.3.7-py3-none-any.whl (33 kB)\n",
            "Collecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-2.2.0-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from cufflinks>=0.17.0->pycaret) (1.15.0)\n",
            "Requirement already satisfied: setuptools>=34.4.1 in /usr/local/lib/python3.7/dist-packages (from cufflinks>=0.17.0->pycaret) (57.2.0)\n",
            "Requirement already satisfied: colorlover>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from cufflinks>=0.17.0->pycaret) (0.3.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim<4.0.0->pycaret) (5.1.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret) (1.0.18)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret) (2.6.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret) (5.0.5)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret) (0.8.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from IPython->pycaret) (4.4.2)\n",
            "Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->pycaret) (3.5.1)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->pycaret) (4.10.1)\n",
            "Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->pycaret) (5.1.3)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->pycaret) (1.0.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets->pycaret) (5.3.5)\n",
            "Requirement already satisfied: tornado>=4.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel>=4.5.1->ipywidgets->pycaret) (5.1.1)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from lightgbm>=2.3.1->pycaret) (0.36.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pycaret) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pycaret) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pycaret) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->pycaret) (2.8.1)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->pycaret) (0.2.0)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->pycaret) (4.7.1)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.7/dist-packages (from nbformat>=4.2.0->ipywidgets->pycaret) (2.6.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->pycaret) (2018.9)\n",
            "Collecting visions[type_image_path]==0.7.1\n",
            "  Downloading visions-0.7.1-py3-none-any.whl (102 kB)\n",
            "\u001b[K     |████████████████████████████████| 102 kB 50.5 MB/s \n",
            "\u001b[?25hCollecting htmlmin>=0.1.12\n",
            "  Downloading htmlmin-0.1.12.tar.gz (19 kB)\n",
            "Collecting pydantic>=1.8.1\n",
            "  Downloading pydantic-1.8.2-cp37-cp37m-manylinux2014_x86_64.whl (10.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 46.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: missingno>=0.4.2 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling>=2.8.0->pycaret) (0.5.0)\n",
            "Collecting tqdm>=4.48.2\n",
            "  Downloading tqdm-4.61.2-py2.py3-none-any.whl (76 kB)\n",
            "\u001b[K     |████████████████████████████████| 76 kB 3.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jinja2>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from pandas-profiling>=2.8.0->pycaret) (2.11.3)\n",
            "Collecting tangled-up-in-unicode==0.1.0\n",
            "  Downloading tangled_up_in_unicode-0.1.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 37.8 MB/s \n",
            "\u001b[?25hCollecting PyYAML>=5.0.0\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 46.0 MB/s \n",
            "\u001b[?25hCollecting requests>=2.24.0\n",
            "  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
            "\u001b[K     |████████████████████████████████| 62 kB 632 kB/s \n",
            "\u001b[?25hCollecting phik>=0.11.1\n",
            "  Downloading phik-0.11.2.tar.gz (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 37.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: bottleneck in /usr/local/lib/python3.7/dist-packages (from visions[type_image_path]==0.7.1->pandas-profiling>=2.8.0->pycaret) (1.3.2)\n",
            "Requirement already satisfied: attrs>=19.3.0 in /usr/local/lib/python3.7/dist-packages (from visions[type_image_path]==0.7.1->pandas-profiling>=2.8.0->pycaret) (21.2.0)\n",
            "Collecting multimethod==1.4\n",
            "  Downloading multimethod-1.4-py2.py3-none-any.whl (7.3 kB)\n",
            "Requirement already satisfied: networkx>=2.4 in /usr/local/lib/python3.7/dist-packages (from visions[type_image_path]==0.7.1->pandas-profiling>=2.8.0->pycaret) (2.5.1)\n",
            "Collecting imagehash\n",
            "  Downloading ImageHash-4.2.1.tar.gz (812 kB)\n",
            "\u001b[K     |████████████████████████████████| 812 kB 26.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from visions[type_image_path]==0.7.1->pandas-profiling>=2.8.0->pycaret) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.11.1->pandas-profiling>=2.8.0->pycaret) (2.0.1)\n",
            "Collecting scipy<=1.5.4\n",
            "  Downloading scipy-1.5.4-cp37-cp37m-manylinux1_x86_64.whl (25.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 25.9 MB 684 bytes/s \n",
            "\u001b[?25hRequirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly>=4.4.1->pycaret) (1.3.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython->pycaret) (0.2.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from pydantic>=1.8.1->pandas-profiling>=2.8.0->pycaret) (3.7.4.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->pandas-profiling>=2.8.0->pycaret) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->pandas-profiling>=2.8.0->pycaret) (2021.5.30)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->pandas-profiling>=2.8.0->pycaret) (2.10)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.7/dist-packages (from requests>=2.24.0->pandas-profiling>=2.8.0->pycaret) (2.0.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (1.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (2.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (0.4.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (1.0.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (3.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (1.1.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (0.8.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<2.4.0->pycaret) (7.4.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy<2.4.0->pycaret) (4.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy<2.4.0->pycaret) (3.5.0)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.7/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets->pycaret) (5.3.1)\n",
            "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (1.7.1)\n",
            "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.10.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (5.6.1)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets->pycaret) (22.1.0)\n",
            "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.7.0)\n",
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.7/dist-packages (from imagehash->visions[type_image_path]==0.7.1->pandas-profiling>=2.8.0->pycaret) (1.1.1)\n",
            "Collecting prometheus-flask-exporter\n",
            "  Downloading prometheus_flask_exporter-0.18.2.tar.gz (22 kB)\n",
            "Requirement already satisfied: protobuf>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (3.17.3)\n",
            "Collecting gitpython>=2.1.0\n",
            "  Downloading GitPython-3.1.18-py3-none-any.whl (170 kB)\n",
            "\u001b[K     |████████████████████████████████| 170 kB 49.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sqlalchemy in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (1.4.20)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (7.1.2)\n",
            "Collecting alembic<=1.4.1\n",
            "  Downloading alembic-1.4.1.tar.gz (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 42.0 MB/s \n",
            "\u001b[?25hCollecting gunicorn\n",
            "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 6.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: sqlparse>=0.3.1 in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (0.4.1)\n",
            "Collecting docker>=4.0.0\n",
            "  Downloading docker-5.0.0-py2.py3-none-any.whl (146 kB)\n",
            "\u001b[K     |████████████████████████████████| 146 kB 54.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (21.0)\n",
            "Requirement already satisfied: Flask in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (1.1.4)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (0.3)\n",
            "Collecting querystring-parser\n",
            "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
            "Collecting databricks-cli>=0.8.7\n",
            "  Downloading databricks-cli-0.14.3.tar.gz (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 2.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from mlflow->pycaret) (1.3.0)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.1.4-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 3.3 MB/s \n",
            "\u001b[?25hCollecting python-editor>=0.3\n",
            "  Downloading python_editor-1.0.4-py3-none-any.whl (4.9 kB)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from databricks-cli>=0.8.7->mlflow->pycaret) (0.8.9)\n",
            "Collecting websocket-client>=0.32.0\n",
            "  Downloading websocket_client-1.1.0-py2.py3-none-any.whl (68 kB)\n",
            "\u001b[K     |████████████████████████████████| 68 kB 4.6 MB/s \n",
            "\u001b[?25hCollecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.7-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.3 MB/s \n",
            "\u001b[?25hCollecting smmap<5,>=3.0.1\n",
            "  Downloading smmap-4.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy->mlflow->pycaret) (1.1.0)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow->pycaret) (1.0.1)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from Flask->mlflow->pycaret) (1.1.0)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.8.4)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (1.4.3)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.7.1)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (3.3.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.5.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pycaret) (0.5.1)\n",
            "Requirement already satisfied: prometheus_client in /usr/local/lib/python3.7/dist-packages (from prometheus-flask-exporter->mlflow->pycaret) (0.11.0)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from pyLDAvis->pycaret) (2.7.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyLDAvis->pycaret) (0.16.0)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from pyLDAvis->pycaret) (0.0)\n",
            "Collecting pyLDAvis\n",
            "  Downloading pyLDAvis-3.3.0.tar.gz (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 48.8 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "  Downloading pyLDAvis-3.2.2.tar.gz (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 38.2 MB/s \n",
            "\u001b[?25hCollecting funcy\n",
            "  Downloading funcy-1.16-py2.py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: numba>=0.35 in /usr/local/lib/python3.7/dist-packages (from pyod->pycaret) (0.51.2)\n",
            "Requirement already satisfied: statsmodels in /usr/local/lib/python3.7/dist-packages (from pyod->pycaret) (0.10.2)\n",
            "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.35->pyod->pycaret) (0.34.0)\n",
            "Requirement already satisfied: patsy>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from statsmodels->pyod->pycaret) (0.5.1)\n",
            "Collecting pynndescent>=0.5\n",
            "  Downloading pynndescent-0.5.4.tar.gz (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 28.2 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: htmlmin, phik, imagehash, alembic, databricks-cli, prometheus-flask-exporter, pyLDAvis, pyod, umap-learn, pynndescent\n",
            "  Building wheel for htmlmin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for htmlmin: filename=htmlmin-0.1.12-py3-none-any.whl size=27098 sha256=efa68a5aef7381e3c62e08f1d9b1fb25b450587f38bdc0840df79e1efed1c986\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/e1/52/5b14d250ba868768823940c3229e9950d201a26d0bd3ee8655\n",
            "  Building wheel for phik (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for phik: filename=phik-0.11.2-py3-none-any.whl size=1107437 sha256=2a11d56ebd86ccdde0eb66dd6c17e18b5ba3ee88a7b5752f0c9e4212c26806f4\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/98/a3/b654f24edcdcdb87d1f70d65a506fcfdf15289db129c594bcd\n",
            "  Building wheel for imagehash (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for imagehash: filename=ImageHash-4.2.1-py2.py3-none-any.whl size=295206 sha256=0801a98506f60c32aa7dcd2053592ae8c633b72eb3c7bbac5d577e82a7451603\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/d5/59/5e3e297533ddb09407769762985d134135064c6831e29a914e\n",
            "  Building wheel for alembic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for alembic: filename=alembic-1.4.1-py2.py3-none-any.whl size=158170 sha256=6b4af51e7a80541502c82fad1d3726faeba9feaac7e8ede42dcec58503185941\n",
            "  Stored in directory: /root/.cache/pip/wheels/be/5d/0a/9e13f53f4f5dfb67cd8d245bb7cdffe12f135846f491a283e3\n",
            "  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for databricks-cli: filename=databricks_cli-0.14.3-py3-none-any.whl size=100557 sha256=017c19583f05eee29d2e84b91c9150531dad4170b18627b2889370922cc82544\n",
            "  Stored in directory: /root/.cache/pip/wheels/3b/60/14/6930445b08959fbdf4e3029bac7e1f2cccb2e94df8afa00b29\n",
            "  Building wheel for prometheus-flask-exporter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for prometheus-flask-exporter: filename=prometheus_flask_exporter-0.18.2-py3-none-any.whl size=17416 sha256=5679e45eae4eb2b7cfd2fefc04675510d830f4900b15c0e649ec9fe210d594b4\n",
            "  Stored in directory: /root/.cache/pip/wheels/6a/1e/1c/c765920cb92b2f0343d2dd8b481a407cee2823f9b4bbd2e52a\n",
            "  Building wheel for pyLDAvis (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyLDAvis: filename=pyLDAvis-3.2.2-py2.py3-none-any.whl size=135618 sha256=ae08d9fce45548cb959d064446d795b335f6ac82294381b827500f5998233133\n",
            "  Stored in directory: /root/.cache/pip/wheels/f8/b1/9b/560ac1931796b7303f7b517b949d2d31a4fbc512aad3b9f284\n",
            "  Building wheel for pyod (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyod: filename=pyod-0.9.0-py3-none-any.whl size=122560 sha256=8453866a6796e66c470970ee839f84e1df61cdd9a9e0c3ce5cdf093a76160259\n",
            "  Stored in directory: /root/.cache/pip/wheels/42/5f/59/5984a6116a4d19aee28d8ebeffd431364ce1cf21eb73a6ad34\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.1-py3-none-any.whl size=76566 sha256=8a5f7d0c22deef236841116905d45ad98b8ddd645fb097b001bd6d4a39a1d482\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/e7/bb/347dc0e510803d7116a13d592b10cc68262da56a8eec4dd72f\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynndescent: filename=pynndescent-0.5.4-py3-none-any.whl size=52372 sha256=f84dcbd06f644ba03d3d1266cd4ea7d09f0a9cfc68b97b3dcda48b8eaf4ce9ca\n",
            "  Stored in directory: /root/.cache/pip/wheels/d0/5b/62/3401692ddad12324249c774c4b15ccb046946021e2b581c043\n",
            "Successfully built htmlmin phik imagehash alembic databricks-cli prometheus-flask-exporter pyLDAvis pyod umap-learn pynndescent\n",
            "Installing collected packages: threadpoolctl, tangled-up-in-unicode, smmap, scipy, multimethod, websocket-client, visions, tqdm, scikit-learn, requests, python-editor, Mako, imagehash, gitdb, querystring-parser, PyYAML, pynndescent, pydantic, prometheus-flask-exporter, phik, htmlmin, gunicorn, gitpython, funcy, docker, databricks-cli, alembic, yellowbrick, umap-learn, scikit-plot, pyod, pyLDAvis, pandas-profiling, mlxtend, mlflow, lightgbm, kmodes, imbalanced-learn, Boruta, pycaret\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.41.1\n",
            "    Uninstalling tqdm-4.41.1:\n",
            "      Successfully uninstalled tqdm-4.41.1\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 0.22.2.post1\n",
            "    Uninstalling scikit-learn-0.22.2.post1:\n",
            "      Successfully uninstalled scikit-learn-0.22.2.post1\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.23.0\n",
            "    Uninstalling requests-2.23.0:\n",
            "      Successfully uninstalled requests-2.23.0\n",
            "  Attempting uninstall: PyYAML\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: yellowbrick\n",
            "    Found existing installation: yellowbrick 0.9.1\n",
            "    Uninstalling yellowbrick-0.9.1:\n",
            "      Successfully uninstalled yellowbrick-0.9.1\n",
            "  Attempting uninstall: pandas-profiling\n",
            "    Found existing installation: pandas-profiling 1.4.1\n",
            "    Uninstalling pandas-profiling-1.4.1:\n",
            "      Successfully uninstalled pandas-profiling-1.4.1\n",
            "  Attempting uninstall: mlxtend\n",
            "    Found existing installation: mlxtend 0.14.0\n",
            "    Uninstalling mlxtend-0.14.0:\n",
            "      Successfully uninstalled mlxtend-0.14.0\n",
            "  Attempting uninstall: lightgbm\n",
            "    Found existing installation: lightgbm 2.2.3\n",
            "    Uninstalling lightgbm-2.2.3:\n",
            "      Successfully uninstalled lightgbm-2.2.3\n",
            "  Attempting uninstall: imbalanced-learn\n",
            "    Found existing installation: imbalanced-learn 0.4.3\n",
            "    Uninstalling imbalanced-learn-0.4.3:\n",
            "      Successfully uninstalled imbalanced-learn-0.4.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests~=2.23.0, but you have requests 2.26.0 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed Boruta-0.3 Mako-1.1.4 PyYAML-5.4.1 alembic-1.4.1 databricks-cli-0.14.3 docker-5.0.0 funcy-1.16 gitdb-4.0.7 gitpython-3.1.18 gunicorn-20.1.0 htmlmin-0.1.12 imagehash-4.2.1 imbalanced-learn-0.7.0 kmodes-0.11.0 lightgbm-3.2.1 mlflow-1.19.0 mlxtend-0.18.0 multimethod-1.4 pandas-profiling-3.0.0 phik-0.11.2 prometheus-flask-exporter-0.18.2 pyLDAvis-3.2.2 pycaret-2.3.2 pydantic-1.8.2 pynndescent-0.5.4 pyod-0.9.0 python-editor-1.0.4 querystring-parser-1.2.4 requests-2.26.0 scikit-learn-0.23.2 scikit-plot-0.3.7 scipy-1.5.4 smmap-4.0.0 tangled-up-in-unicode-0.1.0 threadpoolctl-2.2.0 tqdm-4.61.2 umap-learn-0.5.1 visions-0.7.1 websocket-client-1.1.0 yellowbrick-1.3.post1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIy20cepmFM8"
      },
      "source": [
        "## Rankeamento dos fundos:\n",
        "\n",
        "Para fazermos o rankeamento dos fundos, a fim de descobrir quais são os melhores no mercado brasileiro, escolhemos a estratégia de atribuir uma nota para cada um deles, que levará em consideração tanto os atributos atuais de cada um, como sua performance ao longo dos anos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPEPxiMOm81X"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Primeiramente, vamos pegar o CSV com atributos atuais dos fundos, que ficará na variável df, e os CSVs com atributos históricos, que ficarão na lista dfs_old:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYc8tWGCrFd0"
      },
      "source": [
        "#Recebendo o CSV dos fundos\n",
        "\n",
        "url = 'https://raw.githubusercontent.com/TailUFPB/fundos-imobiliarios/main/CSV_Modelo.csv'\n",
        "data = pd.read_csv(url)\n",
        "df = pd.DataFrame(data)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wHJK_8z7MZN"
      },
      "source": [
        "datas = ['202012', '202009', '202003', '201902', '201812', '201809', '201806', '201803', '201712']\n",
        "dfs_old = []\n",
        "\n",
        "for i in datas:\n",
        "  url = 'https://raw.githubusercontent.com/TailUFPB/fundos-imobiliarios/main/CSV_Antigos_PreProc/' + i + '.csv'\n",
        "  data = pd.read_csv(url)\n",
        "  dfs_old.append(pd.DataFrame(data))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1UnHj2AytiE"
      },
      "source": [
        "pd.set_option(\"display.max_rows\", None)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xzzil78naRW"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "Agora, vamos definir as funções que iremos utilizar para obter a nota de cada fundo:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NrLrxY_jI-cy"
      },
      "source": [
        "Na função *NotaInicial*, iremos usar alguns atributos do fundo para dar uma nota inicial a ele, e faremos isso subtraindo o valor de alguns campos de cada fundo com a média de todos no dataset, e multiplicando o valor por um peso dado a cada atributo baseado na sua importância para a avaliação do fundo, ou seja, se o peso do campo for positivo, quanto maior for o valor do atributo, melhor nota obterá, e caso seja negativo, o contrário. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efW3AH3Pr5jB"
      },
      "source": [
        "#Dando notas para colunas que não tem delimitador definido (Quanto mais alto ou mais baixo, melhor)\n",
        "def NotaInicial(df):\n",
        "  pesos = {'Variação Preço': 0.6, 'Rentab.Período': 0.3, 'PatrimônioLíq.': 0.15,'Liquidez Diária': 0.7,'Rentab.Acumulada': 0.75, 'VPA': 0.25,'QuantidadeAtivos': 0.45, 'VacânciaFísica': -0.65}\n",
        "  colunas = ['Liquidez Diária' , 'Variação Preço','Rentab.Período','Rentab.Acumulada', 'PatrimônioLíq.', 'VPA','QuantidadeAtivos', 'VacânciaFísica']\n",
        "\n",
        "  i = 0\n",
        "  notas = []\n",
        "\n",
        "  while i < df.shape[0]:\n",
        "\n",
        "    nota_row = 0\n",
        "    for j in colunas:\n",
        "      if j in df.columns:\n",
        "        nota_row += pesos[j] * (df.loc[i, j] - df[j].mean())\n",
        "    \n",
        "    notas.append(nota_row)\n",
        "\n",
        "    i += 1\n",
        "\n",
        "  df['Notas'] = notas\n",
        "\n",
        "  return df"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwspWbKTKEaZ"
      },
      "source": [
        "A função *PVPA* funciona de forma parecida, porém ao invés de comparar o atributo com a média do dataset, compara com um valor ideal, multiplica pelo peso e se subtrai da nota total, ou seja, quanto mais perto do valor ideal, melhor para o fundo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsGiI_KQMVwP"
      },
      "source": [
        "#Dando notas para colunas que tem delimitador definido (Quanto mais perto do valor ideal, melhor)\n",
        "def PVPA(df):\n",
        "  pesos2 = {'P/VPA': 0.7}\n",
        "  ideal_value = {'P/VPA': 0.67346938}\n",
        "  colunas = ['P/VPA']\n",
        "\n",
        "  for i in range(df.shape[0]):\n",
        "\n",
        "    for j in colunas:\n",
        "      df.loc[i, 'Notas'] -= pesos2[j] * abs(df.loc[i, j] - ideal_value[j])\n",
        "\n",
        "  return df"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSui8JqdKPIk"
      },
      "source": [
        "Para obter a nota do fundo no momento atual dele, a última função que vamos usar é a *DividendAnalysis*, que dividirá o dataset em quartis baseados na sua performance nos campos relacionados a Dividend Yield, e multiplicando o valor dado a cada quartil por um peso de cada atributo, (de quanto mais tempo for a média do yield, maior o peso) será obtido um resultado, que será somado à nota do campo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7io6yirFh7U"
      },
      "source": [
        "def DividendAnalysis(df):\n",
        "  d = df[\"DividendYield\"].describe()\n",
        "  d_3 = df[\"DY (3M)Média\"].describe()\n",
        "  d_6 = df[\"DY (6M)Média\"].describe()\n",
        "  d_12 = df[\"DY (12M)Média\"].describe()\n",
        "\n",
        "  for column in [\"DividendYield\", \"DY (3M)Média\", \"DY (6M)Média\", \"DY (12M)Média\"]:\n",
        "\n",
        "    if column == \"DividendYield\":\n",
        "      x = 1/22\n",
        "    elif column == \"DY (3M)Média\":\n",
        "      x = 3/22\n",
        "    elif column == \"DY (6M)Média\":\n",
        "      x = 6/22\n",
        "    else:\n",
        "      x = 12/22\n",
        "\n",
        "    for i in range(df.shape[0]):\n",
        "      if df[column].iloc[i] < df[column].describe()[\"25%\"]:\n",
        "        df.loc[i, 'Notas'] += 0*x\n",
        "      elif df[column].iloc[i] >= df[column].describe()[\"25%\"] and df[column].iloc[i] < df[column].describe()[\"50%\"]:\n",
        "        df.loc[i, 'Notas'] += 0.4*x\n",
        "      elif df[column].iloc[i] >= df[column].describe()[\"50%\"] and df[column].iloc[i] < df[column].describe()[\"75%\"]:\n",
        "        df.loc[i, 'Notas'] += 0.8*x\n",
        "      elif df[column].iloc[i] >= df[column].describe()[\"75%\"]:\n",
        "        df.loc[i, 'Notas'] += 1.25*x\n",
        "  \n",
        "  return df"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vh6hLomTLlXt"
      },
      "source": [
        "Por fim, para obtermos uma análise mais completa, vamos levar em consideração também a performance histórica de cada fundo, somando-se à nota original do fundo a que ele obteve no passado, após mutiplicá-la por um peso, que é menor quanto mais distante estiver do momento atual."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RVreFwkvXH_"
      },
      "source": [
        "def AdaptarNota(df, old_dfs):\n",
        "  pesos_data = {'202012': 1/3, '202009': 1/6, '202003': 1/12, '201912': 1/15, '201902': 1/24, '201812': 1/26, '201809': 1/29, '201806': 1/32, '201803': 1/35, '201712': 1/38}\n",
        "\n",
        "  for index, row in df.iterrows():\n",
        "    \n",
        "    df_fundo = old_dfs.loc[old_dfs['Códigodo fundo'] == df.loc[index, 'Códigodo fundo'], ['Notas', 'Ano/Mês']]\n",
        "\n",
        "    if df_fundo.empty:\n",
        "      continue\n",
        "  \n",
        "    for index_old, row_old in df_fundo.iterrows():\n",
        "      df.loc[index, 'Notas'] += df_fundo.loc[index_old, 'Notas'] * pesos_data[str(df_fundo.loc[index_old, 'Ano/Mês'])]\n",
        "\n",
        "  return df"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Xfqtmo8NiEz"
      },
      "source": [
        "Com as funções definidas, podemos começar nossa análise aplicando as três funções iniciais ao nosso dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PW27MTphttkb"
      },
      "source": [
        "df = NotaInicial(df)\n",
        "df = PVPA(df)\n",
        "df = DividendAnalysis(df)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "62dCr5_0Np32"
      },
      "source": [
        "E também aos datasets do passado:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "by8ySKACThbI"
      },
      "source": [
        "for i in range(len(dfs_old)):\n",
        "  dfs_old[i].drop('Unnamed: 0', axis='columns', inplace=True)\n",
        "  dfs_old[i] = NotaInicial(dfs_old[i])\n",
        "  dfs_old[i] = PVPA(dfs_old[i])\n",
        "  dfs_old[i] = DividendAnalysis(dfs_old[i])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmE3Y5wHNuYj"
      },
      "source": [
        "Depois, concatenamos todos os datasets do passado em um só, e chamamos a função *AdaptarNota*, assim, obtendo a nota final de cada fundo imobiliário:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94JlLTGjADax"
      },
      "source": [
        "dfs_old = pd.concat(dfs_old)\n",
        "dfs_old.reset_index(drop=True, inplace=True)\n",
        "df = AdaptarNota(df, dfs_old)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6wupewXNOCeR"
      },
      "source": [
        "E ficamos com o seguinte rankeamento dos fundos:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hlKhNneJnjUG"
      },
      "source": [
        "df_sort = df.sort_values('Notas', ascending=False)\n",
        "df_sort.reset_index(drop=True, inplace=True)\n",
        "df_sort = df_sort[['Códigodo fundo', 'Setor', 'Preço Atual', 'Notas']]"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "LOlrwiheBZNn",
        "outputId": "bce5e91a-5079-42a0-ef98-7174cb6c45ac"
      },
      "source": [
        "df_sort"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Códigodo fundo</th>\n",
              "      <th>Setor</th>\n",
              "      <th>Preço Atual</th>\n",
              "      <th>Notas</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BBPO11</td>\n",
              "      <td>Lajes Corporativas</td>\n",
              "      <td>114.10</td>\n",
              "      <td>2.642532</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>IRDM11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>131.39</td>\n",
              "      <td>2.419633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>RECR11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>101.55</td>\n",
              "      <td>2.412386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CPTS11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>99.60</td>\n",
              "      <td>2.358630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>HABT11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>124.66</td>\n",
              "      <td>2.161607</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>TGAR11</td>\n",
              "      <td>Outros</td>\n",
              "      <td>137.13</td>\n",
              "      <td>2.157821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>BBRC11</td>\n",
              "      <td>Outros</td>\n",
              "      <td>116.00</td>\n",
              "      <td>2.116562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>BNFS11</td>\n",
              "      <td>Outros</td>\n",
              "      <td>123.60</td>\n",
              "      <td>2.109137</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>BARI11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>106.70</td>\n",
              "      <td>2.048882</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>BCRI11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>112.25</td>\n",
              "      <td>2.020643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>VRTA11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>111.37</td>\n",
              "      <td>1.992557</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>CVBI11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>104.81</td>\n",
              "      <td>1.979118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>PORD11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>101.68</td>\n",
              "      <td>1.977127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>MFII11</td>\n",
              "      <td>Híbrido</td>\n",
              "      <td>113.90</td>\n",
              "      <td>1.940412</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>ARCT11</td>\n",
              "      <td>Híbrido</td>\n",
              "      <td>108.14</td>\n",
              "      <td>1.930780</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>XPCI11</td>\n",
              "      <td>Outros</td>\n",
              "      <td>100.05</td>\n",
              "      <td>1.929163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>XPSF11</td>\n",
              "      <td>Outros</td>\n",
              "      <td>97.50</td>\n",
              "      <td>1.915921</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>TRXF11</td>\n",
              "      <td>Outros</td>\n",
              "      <td>105.35</td>\n",
              "      <td>1.905679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>KNHY11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>111.05</td>\n",
              "      <td>1.901487</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>FEXC11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>97.85</td>\n",
              "      <td>1.884188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>MXRF11</td>\n",
              "      <td>Híbrido</td>\n",
              "      <td>10.43</td>\n",
              "      <td>1.883941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>RBED11</td>\n",
              "      <td>Outros</td>\n",
              "      <td>146.63</td>\n",
              "      <td>1.881106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>HGRU11</td>\n",
              "      <td>Híbrido</td>\n",
              "      <td>121.94</td>\n",
              "      <td>1.866567</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>VGIP11</td>\n",
              "      <td>Outros</td>\n",
              "      <td>106.83</td>\n",
              "      <td>1.805712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>TORD11</td>\n",
              "      <td>Outros</td>\n",
              "      <td>10.54</td>\n",
              "      <td>1.801683</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>VINO11</td>\n",
              "      <td>Lajes Corporativas</td>\n",
              "      <td>60.30</td>\n",
              "      <td>1.775076</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>RBRY11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>104.49</td>\n",
              "      <td>1.759620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>RBRF11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>89.16</td>\n",
              "      <td>1.753204</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>RBRL11</td>\n",
              "      <td>Logística</td>\n",
              "      <td>106.70</td>\n",
              "      <td>1.727285</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>RBFF11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>68.00</td>\n",
              "      <td>1.702280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>HGCR11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>105.31</td>\n",
              "      <td>1.686025</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>FIIP11B</td>\n",
              "      <td>Logística</td>\n",
              "      <td>194.01</td>\n",
              "      <td>1.680511</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>NEWL11</td>\n",
              "      <td>Híbrido</td>\n",
              "      <td>105.50</td>\n",
              "      <td>1.670228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>OUFF11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>83.00</td>\n",
              "      <td>1.669231</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>MGFF11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>83.00</td>\n",
              "      <td>1.660374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>VCJR11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>102.40</td>\n",
              "      <td>1.624349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>GTWR11</td>\n",
              "      <td>Lajes Corporativas</td>\n",
              "      <td>106.34</td>\n",
              "      <td>1.616851</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>BTLG11</td>\n",
              "      <td>Logística</td>\n",
              "      <td>112.88</td>\n",
              "      <td>1.615202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>RBRR11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>99.90</td>\n",
              "      <td>1.601796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>BPFF11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>78.55</td>\n",
              "      <td>1.590255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>HFOF11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>98.41</td>\n",
              "      <td>1.587658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>RVBI11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>97.36</td>\n",
              "      <td>1.584051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>BCFF11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>85.71</td>\n",
              "      <td>1.578156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>HCTR11</td>\n",
              "      <td>Outros</td>\n",
              "      <td>138.76</td>\n",
              "      <td>1.519675</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>VSLH11</td>\n",
              "      <td>Outros</td>\n",
              "      <td>10.33</td>\n",
              "      <td>1.498805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>CPFF11</td>\n",
              "      <td>Híbrido</td>\n",
              "      <td>83.03</td>\n",
              "      <td>1.493901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>MCCI11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>102.40</td>\n",
              "      <td>1.406297</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>PLCR11</td>\n",
              "      <td>Híbrido</td>\n",
              "      <td>93.55</td>\n",
              "      <td>1.404150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>VTLT11</td>\n",
              "      <td>Logística</td>\n",
              "      <td>108.70</td>\n",
              "      <td>1.403720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>MBRF11</td>\n",
              "      <td>Outros</td>\n",
              "      <td>875.10</td>\n",
              "      <td>1.380575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>ARRI11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>102.46</td>\n",
              "      <td>1.364986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>CBOP11</td>\n",
              "      <td>Lajes Corporativas</td>\n",
              "      <td>72.50</td>\n",
              "      <td>1.363384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>NSLU11</td>\n",
              "      <td>Hospital</td>\n",
              "      <td>244.10</td>\n",
              "      <td>1.361613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>RECT11</td>\n",
              "      <td>Híbrido</td>\n",
              "      <td>81.74</td>\n",
              "      <td>1.354957</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>HGLG11</td>\n",
              "      <td>Logística</td>\n",
              "      <td>169.90</td>\n",
              "      <td>1.340320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>BRCR11</td>\n",
              "      <td>Híbrido</td>\n",
              "      <td>83.37</td>\n",
              "      <td>1.325750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>FATN11</td>\n",
              "      <td>Híbrido</td>\n",
              "      <td>102.32</td>\n",
              "      <td>1.307537</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>RFOF11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>82.21</td>\n",
              "      <td>1.305622</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>OUJP11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>101.50</td>\n",
              "      <td>1.304873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>RBRP11</td>\n",
              "      <td>Outros</td>\n",
              "      <td>85.50</td>\n",
              "      <td>1.296495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>RBIV11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>83.48</td>\n",
              "      <td>1.276447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>XPLG11</td>\n",
              "      <td>Logística</td>\n",
              "      <td>114.10</td>\n",
              "      <td>1.260764</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>BTCR11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>93.90</td>\n",
              "      <td>1.257688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>VILG11</td>\n",
              "      <td>Logística</td>\n",
              "      <td>116.10</td>\n",
              "      <td>1.239170</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>BRCO11</td>\n",
              "      <td>Logística</td>\n",
              "      <td>110.00</td>\n",
              "      <td>1.200012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>GGRC11</td>\n",
              "      <td>Logística</td>\n",
              "      <td>120.00</td>\n",
              "      <td>1.195472</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>FIIB11</td>\n",
              "      <td>Híbrido</td>\n",
              "      <td>500.61</td>\n",
              "      <td>1.172741</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>OULG11</td>\n",
              "      <td>Outros</td>\n",
              "      <td>69.67</td>\n",
              "      <td>1.168108</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>VIFI11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>87.01</td>\n",
              "      <td>1.152488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>EDFO11B</td>\n",
              "      <td>Lajes Corporativas</td>\n",
              "      <td>251.33</td>\n",
              "      <td>1.122426</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>XPIN11</td>\n",
              "      <td>Outros</td>\n",
              "      <td>105.07</td>\n",
              "      <td>1.108692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>KNSC11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>101.57</td>\n",
              "      <td>1.072938</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>CEOC11</td>\n",
              "      <td>Lajes Corporativas</td>\n",
              "      <td>68.53</td>\n",
              "      <td>1.063505</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>QAGR11</td>\n",
              "      <td>Outros</td>\n",
              "      <td>53.74</td>\n",
              "      <td>1.052995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>FCFL11</td>\n",
              "      <td>Outros</td>\n",
              "      <td>112.35</td>\n",
              "      <td>1.051298</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>MGHT11</td>\n",
              "      <td>Hotel</td>\n",
              "      <td>98.37</td>\n",
              "      <td>1.044015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>GCFF11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>95.31</td>\n",
              "      <td>1.039062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>HSAF11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>101.95</td>\n",
              "      <td>1.020853</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>GALG11</td>\n",
              "      <td>Híbrido</td>\n",
              "      <td>109.98</td>\n",
              "      <td>0.988239</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>OURE11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>88.13</td>\n",
              "      <td>0.980395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>LGCP11</td>\n",
              "      <td>Logística</td>\n",
              "      <td>93.40</td>\n",
              "      <td>0.978501</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>VGIR11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>91.63</td>\n",
              "      <td>0.956022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>SDIL11</td>\n",
              "      <td>Logística</td>\n",
              "      <td>94.75</td>\n",
              "      <td>0.955982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>KNRI11</td>\n",
              "      <td>Híbrido</td>\n",
              "      <td>141.54</td>\n",
              "      <td>0.951795</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>CXCE11B</td>\n",
              "      <td>Outros</td>\n",
              "      <td>82.00</td>\n",
              "      <td>0.949283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>HGFF11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>85.05</td>\n",
              "      <td>0.947771</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>EURO11</td>\n",
              "      <td>Logística</td>\n",
              "      <td>208.80</td>\n",
              "      <td>0.935154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>AFCR11</td>\n",
              "      <td>Híbrido</td>\n",
              "      <td>110.30</td>\n",
              "      <td>0.931158</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>JSRE11</td>\n",
              "      <td>Híbrido</td>\n",
              "      <td>90.05</td>\n",
              "      <td>0.930070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>HLOG11</td>\n",
              "      <td>Logística</td>\n",
              "      <td>113.00</td>\n",
              "      <td>0.927874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>MORE11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>87.96</td>\n",
              "      <td>0.923059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>SARE11</td>\n",
              "      <td>Híbrido</td>\n",
              "      <td>100.80</td>\n",
              "      <td>0.912413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>JPPA11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>99.60</td>\n",
              "      <td>0.907460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>MGCR11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>99.30</td>\n",
              "      <td>0.897630</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>NCHB11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>94.86</td>\n",
              "      <td>0.871783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>BCIA11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>96.26</td>\n",
              "      <td>0.842022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>CXRI11</td>\n",
              "      <td>Híbrido</td>\n",
              "      <td>92.15</td>\n",
              "      <td>0.840551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>MFAI11</td>\n",
              "      <td>Híbrido</td>\n",
              "      <td>98.70</td>\n",
              "      <td>0.834181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>QIFF11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>101.18</td>\n",
              "      <td>0.818099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>ALZR11</td>\n",
              "      <td>Logística</td>\n",
              "      <td>128.00</td>\n",
              "      <td>0.781677</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>FAED11</td>\n",
              "      <td>Outros</td>\n",
              "      <td>150.00</td>\n",
              "      <td>0.778135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>XPML11</td>\n",
              "      <td>Shoppings</td>\n",
              "      <td>107.49</td>\n",
              "      <td>0.754637</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>RZTR11</td>\n",
              "      <td>Híbrido</td>\n",
              "      <td>101.20</td>\n",
              "      <td>0.752259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>HGPO11</td>\n",
              "      <td>Lajes Corporativas</td>\n",
              "      <td>222.27</td>\n",
              "      <td>0.751308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>FLRP11</td>\n",
              "      <td>Shoppings</td>\n",
              "      <td>1312.00</td>\n",
              "      <td>0.749990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>XPPR11</td>\n",
              "      <td>Outros</td>\n",
              "      <td>62.80</td>\n",
              "      <td>0.729167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>LVBI11</td>\n",
              "      <td>Logística</td>\n",
              "      <td>105.29</td>\n",
              "      <td>0.710998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>PLRI11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>45.84</td>\n",
              "      <td>0.692669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>HSML11</td>\n",
              "      <td>Shoppings</td>\n",
              "      <td>90.00</td>\n",
              "      <td>0.678874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>PVBI11</td>\n",
              "      <td>Lajes Corporativas</td>\n",
              "      <td>95.30</td>\n",
              "      <td>0.673206</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>HOSI11</td>\n",
              "      <td>Híbrido</td>\n",
              "      <td>80.50</td>\n",
              "      <td>0.644497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>VISC11</td>\n",
              "      <td>Shoppings</td>\n",
              "      <td>108.55</td>\n",
              "      <td>0.633613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>URPR11</td>\n",
              "      <td>Outros</td>\n",
              "      <td>125.77</td>\n",
              "      <td>0.629316</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>MALL11</td>\n",
              "      <td>Shoppings</td>\n",
              "      <td>97.69</td>\n",
              "      <td>0.628442</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>PATL11</td>\n",
              "      <td>Híbrido</td>\n",
              "      <td>88.06</td>\n",
              "      <td>0.615917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>KFOF11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>93.31</td>\n",
              "      <td>0.615047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>KNCR11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>91.92</td>\n",
              "      <td>0.610912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>CRFF11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>73.68</td>\n",
              "      <td>0.610707</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>HREC11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>101.48</td>\n",
              "      <td>0.606712</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>HBRH11</td>\n",
              "      <td>Híbrido</td>\n",
              "      <td>94.00</td>\n",
              "      <td>0.595855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>BMLC11</td>\n",
              "      <td>Lajes Corporativas</td>\n",
              "      <td>90.97</td>\n",
              "      <td>0.588569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>RCRB11</td>\n",
              "      <td>Lajes Corporativas</td>\n",
              "      <td>151.98</td>\n",
              "      <td>0.567273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122</th>\n",
              "      <td>IBFF11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>68.79</td>\n",
              "      <td>0.562905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123</th>\n",
              "      <td>BLMG11</td>\n",
              "      <td>Outros</td>\n",
              "      <td>101.75</td>\n",
              "      <td>0.556727</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124</th>\n",
              "      <td>BLCP11</td>\n",
              "      <td>Outros</td>\n",
              "      <td>98.28</td>\n",
              "      <td>0.550102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>RELG11</td>\n",
              "      <td>Híbrido</td>\n",
              "      <td>97.07</td>\n",
              "      <td>0.544756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>AIEC11</td>\n",
              "      <td>Lajes Corporativas</td>\n",
              "      <td>86.27</td>\n",
              "      <td>0.527587</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>LUGG11</td>\n",
              "      <td>Residencial</td>\n",
              "      <td>95.00</td>\n",
              "      <td>0.476564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>HUSC11</td>\n",
              "      <td>Outros</td>\n",
              "      <td>131.00</td>\n",
              "      <td>0.468695</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129</th>\n",
              "      <td>HGIC11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>106.38</td>\n",
              "      <td>0.467878</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130</th>\n",
              "      <td>RNGO11</td>\n",
              "      <td>Lajes Corporativas</td>\n",
              "      <td>62.00</td>\n",
              "      <td>0.465561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131</th>\n",
              "      <td>VOTS11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>82.97</td>\n",
              "      <td>0.462210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>ABCP11</td>\n",
              "      <td>Shoppings</td>\n",
              "      <td>70.84</td>\n",
              "      <td>0.448962</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133</th>\n",
              "      <td>RDPD11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>84.00</td>\n",
              "      <td>0.418001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134</th>\n",
              "      <td>BZLI11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>14.70</td>\n",
              "      <td>0.414999</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135</th>\n",
              "      <td>LASC11</td>\n",
              "      <td>Shoppings</td>\n",
              "      <td>94.76</td>\n",
              "      <td>0.401312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136</th>\n",
              "      <td>ONEF11</td>\n",
              "      <td>Lajes Corporativas</td>\n",
              "      <td>140.65</td>\n",
              "      <td>0.397624</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137</th>\n",
              "      <td>THRA11</td>\n",
              "      <td>Lajes Corporativas</td>\n",
              "      <td>137.99</td>\n",
              "      <td>0.397313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138</th>\n",
              "      <td>EVBI11</td>\n",
              "      <td>Híbrido</td>\n",
              "      <td>101.99</td>\n",
              "      <td>0.395940</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>139</th>\n",
              "      <td>JRDM11</td>\n",
              "      <td>Shoppings</td>\n",
              "      <td>68.49</td>\n",
              "      <td>0.385901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140</th>\n",
              "      <td>HGBS11</td>\n",
              "      <td>Shoppings</td>\n",
              "      <td>199.78</td>\n",
              "      <td>0.384267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141</th>\n",
              "      <td>TEPP11</td>\n",
              "      <td>Lajes Corporativas</td>\n",
              "      <td>78.00</td>\n",
              "      <td>0.381703</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142</th>\n",
              "      <td>PQDP11</td>\n",
              "      <td>Shoppings</td>\n",
              "      <td>2853.00</td>\n",
              "      <td>0.376121</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>IFIE11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>93.99</td>\n",
              "      <td>0.371534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144</th>\n",
              "      <td>VGHF11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>9.56</td>\n",
              "      <td>0.350820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>SHPH11</td>\n",
              "      <td>Shoppings</td>\n",
              "      <td>828.50</td>\n",
              "      <td>0.323615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>RRCI11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>86.04</td>\n",
              "      <td>0.315680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>VLOL11</td>\n",
              "      <td>Lajes Corporativas</td>\n",
              "      <td>98.99</td>\n",
              "      <td>0.314338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>CXCO11</td>\n",
              "      <td>Lajes Corporativas</td>\n",
              "      <td>102.40</td>\n",
              "      <td>0.312499</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>HAAA11</td>\n",
              "      <td>Lajes Corporativas</td>\n",
              "      <td>101.00</td>\n",
              "      <td>0.310465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>HGRE11</td>\n",
              "      <td>Lajes Corporativas</td>\n",
              "      <td>126.60</td>\n",
              "      <td>0.306092</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151</th>\n",
              "      <td>HSLG11</td>\n",
              "      <td>Logística</td>\n",
              "      <td>105.49</td>\n",
              "      <td>0.303210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152</th>\n",
              "      <td>BTAL11</td>\n",
              "      <td>Outros</td>\n",
              "      <td>101.56</td>\n",
              "      <td>0.285051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153</th>\n",
              "      <td>RZAK11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>94.55</td>\n",
              "      <td>0.283000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154</th>\n",
              "      <td>BREV11</td>\n",
              "      <td>Híbrido</td>\n",
              "      <td>106.51</td>\n",
              "      <td>0.270125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155</th>\n",
              "      <td>HPDP11</td>\n",
              "      <td>Shoppings</td>\n",
              "      <td>82.48</td>\n",
              "      <td>0.243620</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156</th>\n",
              "      <td>BICR11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>94.91</td>\n",
              "      <td>0.238912</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157</th>\n",
              "      <td>SADI11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>86.50</td>\n",
              "      <td>0.218763</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>158</th>\n",
              "      <td>BBFO11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>87.98</td>\n",
              "      <td>0.216298</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159</th>\n",
              "      <td>PLOG11</td>\n",
              "      <td>Logística</td>\n",
              "      <td>94.32</td>\n",
              "      <td>0.204267</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>160</th>\n",
              "      <td>PQAG11</td>\n",
              "      <td>Logística</td>\n",
              "      <td>63.39</td>\n",
              "      <td>0.192990</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161</th>\n",
              "      <td>IFID11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>94.42</td>\n",
              "      <td>0.136467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162</th>\n",
              "      <td>ATSA11</td>\n",
              "      <td>Shoppings</td>\n",
              "      <td>107.97</td>\n",
              "      <td>0.123495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>163</th>\n",
              "      <td>RNDP11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>686.00</td>\n",
              "      <td>0.122635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164</th>\n",
              "      <td>DEVA11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>108.50</td>\n",
              "      <td>0.119110</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165</th>\n",
              "      <td>RBDS11</td>\n",
              "      <td>Residencial</td>\n",
              "      <td>20.85</td>\n",
              "      <td>0.108807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td>JFLL11</td>\n",
              "      <td>Residencial</td>\n",
              "      <td>94.02</td>\n",
              "      <td>0.091783</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>BLMR11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>82.50</td>\n",
              "      <td>0.090272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>168</th>\n",
              "      <td>SEQR11</td>\n",
              "      <td>Outros</td>\n",
              "      <td>80.49</td>\n",
              "      <td>0.050392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>169</th>\n",
              "      <td>PRSV11</td>\n",
              "      <td>Lajes Corporativas</td>\n",
              "      <td>142.00</td>\n",
              "      <td>0.010427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>170</th>\n",
              "      <td>RECX11</td>\n",
              "      <td>Outros</td>\n",
              "      <td>100.00</td>\n",
              "      <td>-0.005694</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171</th>\n",
              "      <td>NVHO11</td>\n",
              "      <td>Hospital</td>\n",
              "      <td>14.02</td>\n",
              "      <td>-0.012551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>PATC11</td>\n",
              "      <td>Lajes Corporativas</td>\n",
              "      <td>67.76</td>\n",
              "      <td>-0.021317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>VSHO11</td>\n",
              "      <td>Shoppings</td>\n",
              "      <td>77.14</td>\n",
              "      <td>-0.047702</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>FVPQ11</td>\n",
              "      <td>Shoppings</td>\n",
              "      <td>136.53</td>\n",
              "      <td>-0.073589</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>RBRS11</td>\n",
              "      <td>Híbrido</td>\n",
              "      <td>74.80</td>\n",
              "      <td>-0.120152</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>RBCO11</td>\n",
              "      <td>Lajes Corporativas</td>\n",
              "      <td>57.50</td>\n",
              "      <td>-0.131428</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>KISU11</td>\n",
              "      <td>Títulos e Val. Mob.</td>\n",
              "      <td>115.68</td>\n",
              "      <td>-0.132223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178</th>\n",
              "      <td>FPAB11</td>\n",
              "      <td>Lajes Corporativas</td>\n",
              "      <td>258.80</td>\n",
              "      <td>-0.149568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179</th>\n",
              "      <td>FIGS11</td>\n",
              "      <td>Shoppings</td>\n",
              "      <td>59.66</td>\n",
              "      <td>-0.172179</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180</th>\n",
              "      <td>WPLZ11</td>\n",
              "      <td>Shoppings</td>\n",
              "      <td>66.69</td>\n",
              "      <td>-0.236836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>181</th>\n",
              "      <td>DRIT11B</td>\n",
              "      <td>Lajes Corporativas</td>\n",
              "      <td>116.00</td>\n",
              "      <td>-0.310561</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>182</th>\n",
              "      <td>SCPF11</td>\n",
              "      <td>Shoppings</td>\n",
              "      <td>9.12</td>\n",
              "      <td>-0.376116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>183</th>\n",
              "      <td>RBVO11</td>\n",
              "      <td>Outros</td>\n",
              "      <td>12.14</td>\n",
              "      <td>-0.524521</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>184</th>\n",
              "      <td>XTED11</td>\n",
              "      <td>Lajes Corporativas</td>\n",
              "      <td>7.13</td>\n",
              "      <td>-0.571691</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>185</th>\n",
              "      <td>RBGS11</td>\n",
              "      <td>Shoppings</td>\n",
              "      <td>37.93</td>\n",
              "      <td>-0.666681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>186</th>\n",
              "      <td>WTSP11B</td>\n",
              "      <td>Híbrido</td>\n",
              "      <td>45.50</td>\n",
              "      <td>-0.712700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>187</th>\n",
              "      <td>FIVN11</td>\n",
              "      <td>Shoppings</td>\n",
              "      <td>2.97</td>\n",
              "      <td>-0.767051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188</th>\n",
              "      <td>NEWU11</td>\n",
              "      <td>Lajes Corporativas</td>\n",
              "      <td>36.48</td>\n",
              "      <td>-0.790015</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189</th>\n",
              "      <td>TRNT11</td>\n",
              "      <td>Lajes Corporativas</td>\n",
              "      <td>149.00</td>\n",
              "      <td>-0.875775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>190</th>\n",
              "      <td>CNES11</td>\n",
              "      <td>Lajes Corporativas</td>\n",
              "      <td>42.61</td>\n",
              "      <td>-1.016564</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>191</th>\n",
              "      <td>EDGA11</td>\n",
              "      <td>Lajes Corporativas</td>\n",
              "      <td>26.77</td>\n",
              "      <td>-1.040911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>ALMI11</td>\n",
              "      <td>Lajes Corporativas</td>\n",
              "      <td>1160.00</td>\n",
              "      <td>-1.103355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>193</th>\n",
              "      <td>XPHT11</td>\n",
              "      <td>Hotel</td>\n",
              "      <td>87.90</td>\n",
              "      <td>-1.470117</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Códigodo fundo                Setor  Preço Atual     Notas\n",
              "0           BBPO11   Lajes Corporativas       114.10  2.642532\n",
              "1           IRDM11  Títulos e Val. Mob.       131.39  2.419633\n",
              "2           RECR11  Títulos e Val. Mob.       101.55  2.412386\n",
              "3           CPTS11  Títulos e Val. Mob.        99.60  2.358630\n",
              "4           HABT11  Títulos e Val. Mob.       124.66  2.161607\n",
              "5           TGAR11               Outros       137.13  2.157821\n",
              "6           BBRC11               Outros       116.00  2.116562\n",
              "7           BNFS11               Outros       123.60  2.109137\n",
              "8           BARI11  Títulos e Val. Mob.       106.70  2.048882\n",
              "9           BCRI11  Títulos e Val. Mob.       112.25  2.020643\n",
              "10          VRTA11  Títulos e Val. Mob.       111.37  1.992557\n",
              "11          CVBI11  Títulos e Val. Mob.       104.81  1.979118\n",
              "12          PORD11  Títulos e Val. Mob.       101.68  1.977127\n",
              "13          MFII11              Híbrido       113.90  1.940412\n",
              "14          ARCT11              Híbrido       108.14  1.930780\n",
              "15          XPCI11               Outros       100.05  1.929163\n",
              "16          XPSF11               Outros        97.50  1.915921\n",
              "17          TRXF11               Outros       105.35  1.905679\n",
              "18          KNHY11  Títulos e Val. Mob.       111.05  1.901487\n",
              "19          FEXC11  Títulos e Val. Mob.        97.85  1.884188\n",
              "20          MXRF11              Híbrido        10.43  1.883941\n",
              "21          RBED11               Outros       146.63  1.881106\n",
              "22          HGRU11              Híbrido       121.94  1.866567\n",
              "23          VGIP11               Outros       106.83  1.805712\n",
              "24          TORD11               Outros        10.54  1.801683\n",
              "25          VINO11   Lajes Corporativas        60.30  1.775076\n",
              "26          RBRY11  Títulos e Val. Mob.       104.49  1.759620\n",
              "27          RBRF11  Títulos e Val. Mob.        89.16  1.753204\n",
              "28          RBRL11            Logística       106.70  1.727285\n",
              "29          RBFF11  Títulos e Val. Mob.        68.00  1.702280\n",
              "30          HGCR11  Títulos e Val. Mob.       105.31  1.686025\n",
              "31         FIIP11B            Logística       194.01  1.680511\n",
              "32          NEWL11              Híbrido       105.50  1.670228\n",
              "33          OUFF11  Títulos e Val. Mob.        83.00  1.669231\n",
              "34          MGFF11  Títulos e Val. Mob.        83.00  1.660374\n",
              "35          VCJR11  Títulos e Val. Mob.       102.40  1.624349\n",
              "36          GTWR11   Lajes Corporativas       106.34  1.616851\n",
              "37          BTLG11            Logística       112.88  1.615202\n",
              "38          RBRR11  Títulos e Val. Mob.        99.90  1.601796\n",
              "39          BPFF11  Títulos e Val. Mob.        78.55  1.590255\n",
              "40          HFOF11  Títulos e Val. Mob.        98.41  1.587658\n",
              "41          RVBI11  Títulos e Val. Mob.        97.36  1.584051\n",
              "42          BCFF11  Títulos e Val. Mob.        85.71  1.578156\n",
              "43          HCTR11               Outros       138.76  1.519675\n",
              "44          VSLH11               Outros        10.33  1.498805\n",
              "45          CPFF11              Híbrido        83.03  1.493901\n",
              "46          MCCI11  Títulos e Val. Mob.       102.40  1.406297\n",
              "47          PLCR11              Híbrido        93.55  1.404150\n",
              "48          VTLT11            Logística       108.70  1.403720\n",
              "49          MBRF11               Outros       875.10  1.380575\n",
              "50          ARRI11  Títulos e Val. Mob.       102.46  1.364986\n",
              "51          CBOP11   Lajes Corporativas        72.50  1.363384\n",
              "52          NSLU11             Hospital       244.10  1.361613\n",
              "53          RECT11              Híbrido        81.74  1.354957\n",
              "54          HGLG11            Logística       169.90  1.340320\n",
              "55          BRCR11              Híbrido        83.37  1.325750\n",
              "56          FATN11              Híbrido       102.32  1.307537\n",
              "57          RFOF11  Títulos e Val. Mob.        82.21  1.305622\n",
              "58          OUJP11  Títulos e Val. Mob.       101.50  1.304873\n",
              "59          RBRP11               Outros        85.50  1.296495\n",
              "60          RBIV11  Títulos e Val. Mob.        83.48  1.276447\n",
              "61          XPLG11            Logística       114.10  1.260764\n",
              "62          BTCR11  Títulos e Val. Mob.        93.90  1.257688\n",
              "63          VILG11            Logística       116.10  1.239170\n",
              "64          BRCO11            Logística       110.00  1.200012\n",
              "65          GGRC11            Logística       120.00  1.195472\n",
              "66          FIIB11              Híbrido       500.61  1.172741\n",
              "67          OULG11               Outros        69.67  1.168108\n",
              "68          VIFI11  Títulos e Val. Mob.        87.01  1.152488\n",
              "69         EDFO11B   Lajes Corporativas       251.33  1.122426\n",
              "70          XPIN11               Outros       105.07  1.108692\n",
              "71          KNSC11  Títulos e Val. Mob.       101.57  1.072938\n",
              "72          CEOC11   Lajes Corporativas        68.53  1.063505\n",
              "73          QAGR11               Outros        53.74  1.052995\n",
              "74          FCFL11               Outros       112.35  1.051298\n",
              "75          MGHT11                Hotel        98.37  1.044015\n",
              "76          GCFF11  Títulos e Val. Mob.        95.31  1.039062\n",
              "77          HSAF11  Títulos e Val. Mob.       101.95  1.020853\n",
              "78          GALG11              Híbrido       109.98  0.988239\n",
              "79          OURE11  Títulos e Val. Mob.        88.13  0.980395\n",
              "80          LGCP11            Logística        93.40  0.978501\n",
              "81          VGIR11  Títulos e Val. Mob.        91.63  0.956022\n",
              "82          SDIL11            Logística        94.75  0.955982\n",
              "83          KNRI11              Híbrido       141.54  0.951795\n",
              "84         CXCE11B               Outros        82.00  0.949283\n",
              "85          HGFF11  Títulos e Val. Mob.        85.05  0.947771\n",
              "86          EURO11            Logística       208.80  0.935154\n",
              "87          AFCR11              Híbrido       110.30  0.931158\n",
              "88          JSRE11              Híbrido        90.05  0.930070\n",
              "89          HLOG11            Logística       113.00  0.927874\n",
              "90          MORE11  Títulos e Val. Mob.        87.96  0.923059\n",
              "91          SARE11              Híbrido       100.80  0.912413\n",
              "92          JPPA11  Títulos e Val. Mob.        99.60  0.907460\n",
              "93          MGCR11  Títulos e Val. Mob.        99.30  0.897630\n",
              "94          NCHB11  Títulos e Val. Mob.        94.86  0.871783\n",
              "95          BCIA11  Títulos e Val. Mob.        96.26  0.842022\n",
              "96          CXRI11              Híbrido        92.15  0.840551\n",
              "97          MFAI11              Híbrido        98.70  0.834181\n",
              "98          QIFF11  Títulos e Val. Mob.       101.18  0.818099\n",
              "99          ALZR11            Logística       128.00  0.781677\n",
              "100         FAED11               Outros       150.00  0.778135\n",
              "101         XPML11            Shoppings       107.49  0.754637\n",
              "102         RZTR11              Híbrido       101.20  0.752259\n",
              "103         HGPO11   Lajes Corporativas       222.27  0.751308\n",
              "104         FLRP11            Shoppings      1312.00  0.749990\n",
              "105         XPPR11               Outros        62.80  0.729167\n",
              "106         LVBI11            Logística       105.29  0.710998\n",
              "107         PLRI11  Títulos e Val. Mob.        45.84  0.692669\n",
              "108         HSML11            Shoppings        90.00  0.678874\n",
              "109         PVBI11   Lajes Corporativas        95.30  0.673206\n",
              "110         HOSI11              Híbrido        80.50  0.644497\n",
              "111         VISC11            Shoppings       108.55  0.633613\n",
              "112         URPR11               Outros       125.77  0.629316\n",
              "113         MALL11            Shoppings        97.69  0.628442\n",
              "114         PATL11              Híbrido        88.06  0.615917\n",
              "115         KFOF11  Títulos e Val. Mob.        93.31  0.615047\n",
              "116         KNCR11  Títulos e Val. Mob.        91.92  0.610912\n",
              "117         CRFF11  Títulos e Val. Mob.        73.68  0.610707\n",
              "118         HREC11  Títulos e Val. Mob.       101.48  0.606712\n",
              "119         HBRH11              Híbrido        94.00  0.595855\n",
              "120         BMLC11   Lajes Corporativas        90.97  0.588569\n",
              "121         RCRB11   Lajes Corporativas       151.98  0.567273\n",
              "122         IBFF11  Títulos e Val. Mob.        68.79  0.562905\n",
              "123         BLMG11               Outros       101.75  0.556727\n",
              "124         BLCP11               Outros        98.28  0.550102\n",
              "125         RELG11              Híbrido        97.07  0.544756\n",
              "126         AIEC11   Lajes Corporativas        86.27  0.527587\n",
              "127         LUGG11          Residencial        95.00  0.476564\n",
              "128         HUSC11               Outros       131.00  0.468695\n",
              "129         HGIC11  Títulos e Val. Mob.       106.38  0.467878\n",
              "130         RNGO11   Lajes Corporativas        62.00  0.465561\n",
              "131         VOTS11  Títulos e Val. Mob.        82.97  0.462210\n",
              "132         ABCP11            Shoppings        70.84  0.448962\n",
              "133         RDPD11  Títulos e Val. Mob.        84.00  0.418001\n",
              "134         BZLI11  Títulos e Val. Mob.        14.70  0.414999\n",
              "135         LASC11            Shoppings        94.76  0.401312\n",
              "136         ONEF11   Lajes Corporativas       140.65  0.397624\n",
              "137         THRA11   Lajes Corporativas       137.99  0.397313\n",
              "138         EVBI11              Híbrido       101.99  0.395940\n",
              "139         JRDM11            Shoppings        68.49  0.385901\n",
              "140         HGBS11            Shoppings       199.78  0.384267\n",
              "141         TEPP11   Lajes Corporativas        78.00  0.381703\n",
              "142         PQDP11            Shoppings      2853.00  0.376121\n",
              "143         IFIE11  Títulos e Val. Mob.        93.99  0.371534\n",
              "144         VGHF11  Títulos e Val. Mob.         9.56  0.350820\n",
              "145         SHPH11            Shoppings       828.50  0.323615\n",
              "146         RRCI11  Títulos e Val. Mob.        86.04  0.315680\n",
              "147         VLOL11   Lajes Corporativas        98.99  0.314338\n",
              "148         CXCO11   Lajes Corporativas       102.40  0.312499\n",
              "149         HAAA11   Lajes Corporativas       101.00  0.310465\n",
              "150         HGRE11   Lajes Corporativas       126.60  0.306092\n",
              "151         HSLG11            Logística       105.49  0.303210\n",
              "152         BTAL11               Outros       101.56  0.285051\n",
              "153         RZAK11  Títulos e Val. Mob.        94.55  0.283000\n",
              "154         BREV11              Híbrido       106.51  0.270125\n",
              "155         HPDP11            Shoppings        82.48  0.243620\n",
              "156         BICR11  Títulos e Val. Mob.        94.91  0.238912\n",
              "157         SADI11  Títulos e Val. Mob.        86.50  0.218763\n",
              "158         BBFO11  Títulos e Val. Mob.        87.98  0.216298\n",
              "159         PLOG11            Logística        94.32  0.204267\n",
              "160         PQAG11            Logística        63.39  0.192990\n",
              "161         IFID11  Títulos e Val. Mob.        94.42  0.136467\n",
              "162         ATSA11            Shoppings       107.97  0.123495\n",
              "163         RNDP11  Títulos e Val. Mob.       686.00  0.122635\n",
              "164         DEVA11  Títulos e Val. Mob.       108.50  0.119110\n",
              "165         RBDS11          Residencial        20.85  0.108807\n",
              "166         JFLL11          Residencial        94.02  0.091783\n",
              "167         BLMR11  Títulos e Val. Mob.        82.50  0.090272\n",
              "168         SEQR11               Outros        80.49  0.050392\n",
              "169         PRSV11   Lajes Corporativas       142.00  0.010427\n",
              "170         RECX11               Outros       100.00 -0.005694\n",
              "171         NVHO11             Hospital        14.02 -0.012551\n",
              "172         PATC11   Lajes Corporativas        67.76 -0.021317\n",
              "173         VSHO11            Shoppings        77.14 -0.047702\n",
              "174         FVPQ11            Shoppings       136.53 -0.073589\n",
              "175         RBRS11              Híbrido        74.80 -0.120152\n",
              "176         RBCO11   Lajes Corporativas        57.50 -0.131428\n",
              "177         KISU11  Títulos e Val. Mob.       115.68 -0.132223\n",
              "178         FPAB11   Lajes Corporativas       258.80 -0.149568\n",
              "179         FIGS11            Shoppings        59.66 -0.172179\n",
              "180         WPLZ11            Shoppings        66.69 -0.236836\n",
              "181        DRIT11B   Lajes Corporativas       116.00 -0.310561\n",
              "182         SCPF11            Shoppings         9.12 -0.376116\n",
              "183         RBVO11               Outros        12.14 -0.524521\n",
              "184         XTED11   Lajes Corporativas         7.13 -0.571691\n",
              "185         RBGS11            Shoppings        37.93 -0.666681\n",
              "186        WTSP11B              Híbrido        45.50 -0.712700\n",
              "187         FIVN11            Shoppings         2.97 -0.767051\n",
              "188         NEWU11   Lajes Corporativas        36.48 -0.790015\n",
              "189         TRNT11   Lajes Corporativas       149.00 -0.875775\n",
              "190         CNES11   Lajes Corporativas        42.61 -1.016564\n",
              "191         EDGA11   Lajes Corporativas        26.77 -1.040911\n",
              "192         ALMI11   Lajes Corporativas      1160.00 -1.103355\n",
              "193         XPHT11                Hotel        87.90 -1.470117"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wzsA28CmpwAv"
      },
      "source": [
        "## Modelo de classificação de fundos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iOhXOvqAON83"
      },
      "source": [
        "Agora, podemos também fazer um modelo de Machine Learning que, com os dados de um fundo em mãos, possa classificá-lo em: bom, médio ou ruim.\n",
        "\n",
        "Para fazer isso, primeiro vamos utilizar os datasets que já temos para treinar o modelo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uXVIjvUv6hgH"
      },
      "source": [
        "dfs_modelo = []\n",
        "url = 'https://raw.githubusercontent.com/TailUFPB/fundos-imobiliarios/main/CSV_Modelo.csv'\n",
        "data = pd.read_csv(url)\n",
        "dfs_modelo.append(pd.DataFrame(data))\n",
        "datas = ['202012', '202009', '202003', '201902']\n",
        "\n",
        "for i in datas:\n",
        "  url = 'https://raw.githubusercontent.com/TailUFPB/fundos-imobiliarios/main/CSV_Antigos_PreProc/' + i + '.csv'\n",
        "  data = pd.read_csv(url)\n",
        "  dfs_modelo.append(pd.DataFrame(data))\n",
        "\n",
        "dfs_modelo[0].drop(['Unnamed: 0', 'Ano/Mês','Setor', 'Preço Atual', 'Dividendo', 'DY Ano'], axis='columns', inplace=True)\n",
        "for i in range(1,len(dfs_modelo)):\n",
        "  #Retirando colunas desnecessárias\n",
        "  dfs_modelo[i].drop(['Unnamed: 0', 'Ano/Mês','Unnamed: 0.1', 'Preço Atual', 'Dividendo', 'DY Ano'], axis='columns', inplace=True)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeibpF7wPp7W"
      },
      "source": [
        "Agora, vamos dar uma nota para todos os fundos desse nosso dataset, utilizando as funções do começo do notebook:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OACRPXq7wiF"
      },
      "source": [
        "for i in range(len(dfs_modelo)):\n",
        "  dfs_modelo[i] = NotaInicial(dfs_modelo[i])\n",
        "  dfs_modelo[i] = PVPA(dfs_modelo[i])\n",
        "  dfs_modelo[i] = DividendAnalysis(dfs_modelo[i])\n",
        "\n",
        "dfs_modelo = pd.concat(dfs_modelo)\n",
        "\n",
        "dfs_modelo = dfs_modelo.sort_values('Notas', ascending=False)\n",
        "dfs_modelo.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wD76G-AhP79y"
      },
      "source": [
        "Levando em consideração a nota obtida de cada modelo, podemos separá-los nas 3 categorias em que queremos classificar:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMaBZRa0_GXn"
      },
      "source": [
        "dfs_modelo['Label'] = ''\n",
        "for index, row in dfs_modelo.iterrows():\n",
        "  if dfs_modelo.loc[index, 'Notas'] <= 0:\n",
        "    dfs_modelo.loc[index,'Label'] = 'Ruim'\n",
        "  elif dfs_modelo.loc[index, 'Notas'] <= 0.85:\n",
        "    dfs_modelo.loc[index,'Label'] = 'Médio'\n",
        "  else:\n",
        "    dfs_modelo.loc[index,'Label'] = 'Bom'\n",
        "\n",
        "dfs_modelo.drop(['Notas'], axis='columns', inplace=True)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RyjZcDQgQPx7"
      },
      "source": [
        "Agora, podemos utilizar a biblioteca Pycaret para aplicar vários modelos de ML nos nossos dados e descobrir qual o que melhor consegue classificá-los:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUh_qecK7jN9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9f46e3e9-99d6-4440-f7f0-36e16fe4cbee"
      },
      "source": [
        "grid = setup(data=dfs_modelo.iloc[:,1:], target='Label', html=False, silent=True, verbose=False)\n",
        "\n",
        "model = compare_models()\n",
        "plot_model(model, plot ='feature_all')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>AUC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Prec.</th>\n",
              "      <th>F1</th>\n",
              "      <th>Kappa</th>\n",
              "      <th>MCC</th>\n",
              "      <th>TT (Sec)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>lr</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.809</td>\n",
              "      <td>0.9346</td>\n",
              "      <td>0.7122</td>\n",
              "      <td>0.8338</td>\n",
              "      <td>0.7965</td>\n",
              "      <td>0.6242</td>\n",
              "      <td>0.6519</td>\n",
              "      <td>0.3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Model  Accuracy     AUC  Recall   Prec.      F1   Kappa  \\\n",
              "lr  Logistic Regression     0.809  0.9346  0.7122  0.8338  0.7965  0.6242   \n",
              "\n",
              "       MCC  TT (Sec)  \n",
              "lr  0.6519       0.3  "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>AUC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Prec.</th>\n",
              "      <th>F1</th>\n",
              "      <th>Kappa</th>\n",
              "      <th>MCC</th>\n",
              "      <th>TT (Sec)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>knn</th>\n",
              "      <td>K Neighbors Classifier</td>\n",
              "      <td>0.862</td>\n",
              "      <td>0.9220</td>\n",
              "      <td>0.8183</td>\n",
              "      <td>0.8711</td>\n",
              "      <td>0.8588</td>\n",
              "      <td>0.7430</td>\n",
              "      <td>0.7522</td>\n",
              "      <td>0.115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lr</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.809</td>\n",
              "      <td>0.9346</td>\n",
              "      <td>0.7122</td>\n",
              "      <td>0.8338</td>\n",
              "      <td>0.7965</td>\n",
              "      <td>0.6242</td>\n",
              "      <td>0.6519</td>\n",
              "      <td>0.300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      Model  Accuracy     AUC  Recall   Prec.      F1   Kappa  \\\n",
              "knn  K Neighbors Classifier     0.862  0.9220  0.8183  0.8711  0.8588  0.7430   \n",
              "lr      Logistic Regression     0.809  0.9346  0.7122  0.8338  0.7965  0.6242   \n",
              "\n",
              "        MCC  TT (Sec)  \n",
              "knn  0.7522     0.115  \n",
              "lr   0.6519     0.300  "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>AUC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Prec.</th>\n",
              "      <th>F1</th>\n",
              "      <th>Kappa</th>\n",
              "      <th>MCC</th>\n",
              "      <th>TT (Sec)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>knn</th>\n",
              "      <td>K Neighbors Classifier</td>\n",
              "      <td>0.8620</td>\n",
              "      <td>0.9220</td>\n",
              "      <td>0.8183</td>\n",
              "      <td>0.8711</td>\n",
              "      <td>0.8588</td>\n",
              "      <td>0.7430</td>\n",
              "      <td>0.7522</td>\n",
              "      <td>0.115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nb</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>0.8091</td>\n",
              "      <td>0.9099</td>\n",
              "      <td>0.7958</td>\n",
              "      <td>0.8167</td>\n",
              "      <td>0.8098</td>\n",
              "      <td>0.6629</td>\n",
              "      <td>0.6658</td>\n",
              "      <td>0.017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lr</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.8090</td>\n",
              "      <td>0.9346</td>\n",
              "      <td>0.7122</td>\n",
              "      <td>0.8338</td>\n",
              "      <td>0.7965</td>\n",
              "      <td>0.6242</td>\n",
              "      <td>0.6519</td>\n",
              "      <td>0.300</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                      Model  Accuracy     AUC  Recall   Prec.      F1   Kappa  \\\n",
              "knn  K Neighbors Classifier    0.8620  0.9220  0.8183  0.8711  0.8588  0.7430   \n",
              "nb              Naive Bayes    0.8091  0.9099  0.7958  0.8167  0.8098  0.6629   \n",
              "lr      Logistic Regression    0.8090  0.9346  0.7122  0.8338  0.7965  0.6242   \n",
              "\n",
              "        MCC  TT (Sec)  \n",
              "knn  0.7522     0.115  \n",
              "nb   0.6658     0.017  \n",
              "lr   0.6519     0.300  "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>AUC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Prec.</th>\n",
              "      <th>F1</th>\n",
              "      <th>Kappa</th>\n",
              "      <th>MCC</th>\n",
              "      <th>TT (Sec)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>knn</th>\n",
              "      <td>K Neighbors Classifier</td>\n",
              "      <td>0.8620</td>\n",
              "      <td>0.9220</td>\n",
              "      <td>0.8183</td>\n",
              "      <td>0.8711</td>\n",
              "      <td>0.8588</td>\n",
              "      <td>0.7430</td>\n",
              "      <td>0.7522</td>\n",
              "      <td>0.115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nb</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>0.8091</td>\n",
              "      <td>0.9099</td>\n",
              "      <td>0.7958</td>\n",
              "      <td>0.8167</td>\n",
              "      <td>0.8098</td>\n",
              "      <td>0.6629</td>\n",
              "      <td>0.6658</td>\n",
              "      <td>0.017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lr</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.8090</td>\n",
              "      <td>0.9346</td>\n",
              "      <td>0.7122</td>\n",
              "      <td>0.8338</td>\n",
              "      <td>0.7965</td>\n",
              "      <td>0.6242</td>\n",
              "      <td>0.6519</td>\n",
              "      <td>0.300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dt</th>\n",
              "      <td>Decision Tree Classifier</td>\n",
              "      <td>0.7832</td>\n",
              "      <td>0.7883</td>\n",
              "      <td>0.7480</td>\n",
              "      <td>0.7872</td>\n",
              "      <td>0.7788</td>\n",
              "      <td>0.6013</td>\n",
              "      <td>0.6070</td>\n",
              "      <td>0.020</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        Model  Accuracy     AUC  Recall   Prec.      F1  \\\n",
              "knn    K Neighbors Classifier    0.8620  0.9220  0.8183  0.8711  0.8588   \n",
              "nb                Naive Bayes    0.8091  0.9099  0.7958  0.8167  0.8098   \n",
              "lr        Logistic Regression    0.8090  0.9346  0.7122  0.8338  0.7965   \n",
              "dt   Decision Tree Classifier    0.7832  0.7883  0.7480  0.7872  0.7788   \n",
              "\n",
              "      Kappa     MCC  TT (Sec)  \n",
              "knn  0.7430  0.7522     0.115  \n",
              "nb   0.6629  0.6658     0.017  \n",
              "lr   0.6242  0.6519     0.300  \n",
              "dt   0.6013  0.6070     0.020  "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>AUC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Prec.</th>\n",
              "      <th>F1</th>\n",
              "      <th>Kappa</th>\n",
              "      <th>MCC</th>\n",
              "      <th>TT (Sec)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>knn</th>\n",
              "      <td>K Neighbors Classifier</td>\n",
              "      <td>0.8620</td>\n",
              "      <td>0.9220</td>\n",
              "      <td>0.8183</td>\n",
              "      <td>0.8711</td>\n",
              "      <td>0.8588</td>\n",
              "      <td>0.7430</td>\n",
              "      <td>0.7522</td>\n",
              "      <td>0.115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nb</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>0.8091</td>\n",
              "      <td>0.9099</td>\n",
              "      <td>0.7958</td>\n",
              "      <td>0.8167</td>\n",
              "      <td>0.8098</td>\n",
              "      <td>0.6629</td>\n",
              "      <td>0.6658</td>\n",
              "      <td>0.017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lr</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.8090</td>\n",
              "      <td>0.9346</td>\n",
              "      <td>0.7122</td>\n",
              "      <td>0.8338</td>\n",
              "      <td>0.7965</td>\n",
              "      <td>0.6242</td>\n",
              "      <td>0.6519</td>\n",
              "      <td>0.300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>svm</th>\n",
              "      <td>SVM - Linear Kernel</td>\n",
              "      <td>0.7961</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.7396</td>\n",
              "      <td>0.8187</td>\n",
              "      <td>0.7854</td>\n",
              "      <td>0.6178</td>\n",
              "      <td>0.6415</td>\n",
              "      <td>0.062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dt</th>\n",
              "      <td>Decision Tree Classifier</td>\n",
              "      <td>0.7832</td>\n",
              "      <td>0.7883</td>\n",
              "      <td>0.7480</td>\n",
              "      <td>0.7872</td>\n",
              "      <td>0.7788</td>\n",
              "      <td>0.6013</td>\n",
              "      <td>0.6070</td>\n",
              "      <td>0.020</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        Model  Accuracy     AUC  Recall   Prec.      F1  \\\n",
              "knn    K Neighbors Classifier    0.8620  0.9220  0.8183  0.8711  0.8588   \n",
              "nb                Naive Bayes    0.8091  0.9099  0.7958  0.8167  0.8098   \n",
              "lr        Logistic Regression    0.8090  0.9346  0.7122  0.8338  0.7965   \n",
              "svm       SVM - Linear Kernel    0.7961  0.0000  0.7396  0.8187  0.7854   \n",
              "dt   Decision Tree Classifier    0.7832  0.7883  0.7480  0.7872  0.7788   \n",
              "\n",
              "      Kappa     MCC  TT (Sec)  \n",
              "knn  0.7430  0.7522     0.115  \n",
              "nb   0.6629  0.6658     0.017  \n",
              "lr   0.6242  0.6519     0.300  \n",
              "svm  0.6178  0.6415     0.062  \n",
              "dt   0.6013  0.6070     0.020  "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>AUC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Prec.</th>\n",
              "      <th>F1</th>\n",
              "      <th>Kappa</th>\n",
              "      <th>MCC</th>\n",
              "      <th>TT (Sec)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>knn</th>\n",
              "      <td>K Neighbors Classifier</td>\n",
              "      <td>0.8620</td>\n",
              "      <td>0.9220</td>\n",
              "      <td>0.8183</td>\n",
              "      <td>0.8711</td>\n",
              "      <td>0.8588</td>\n",
              "      <td>0.7430</td>\n",
              "      <td>0.7522</td>\n",
              "      <td>0.115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nb</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>0.8091</td>\n",
              "      <td>0.9099</td>\n",
              "      <td>0.7958</td>\n",
              "      <td>0.8167</td>\n",
              "      <td>0.8098</td>\n",
              "      <td>0.6629</td>\n",
              "      <td>0.6658</td>\n",
              "      <td>0.017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lr</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.8090</td>\n",
              "      <td>0.9346</td>\n",
              "      <td>0.7122</td>\n",
              "      <td>0.8338</td>\n",
              "      <td>0.7965</td>\n",
              "      <td>0.6242</td>\n",
              "      <td>0.6519</td>\n",
              "      <td>0.300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>svm</th>\n",
              "      <td>SVM - Linear Kernel</td>\n",
              "      <td>0.7961</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.7396</td>\n",
              "      <td>0.8187</td>\n",
              "      <td>0.7854</td>\n",
              "      <td>0.6178</td>\n",
              "      <td>0.6415</td>\n",
              "      <td>0.062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dt</th>\n",
              "      <td>Decision Tree Classifier</td>\n",
              "      <td>0.7832</td>\n",
              "      <td>0.7883</td>\n",
              "      <td>0.7480</td>\n",
              "      <td>0.7872</td>\n",
              "      <td>0.7788</td>\n",
              "      <td>0.6013</td>\n",
              "      <td>0.6070</td>\n",
              "      <td>0.020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ridge</th>\n",
              "      <td>Ridge Classifier</td>\n",
              "      <td>0.7431</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.6083</td>\n",
              "      <td>0.7541</td>\n",
              "      <td>0.7172</td>\n",
              "      <td>0.4792</td>\n",
              "      <td>0.5144</td>\n",
              "      <td>0.015</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          Model  Accuracy     AUC  Recall   Prec.      F1  \\\n",
              "knn      K Neighbors Classifier    0.8620  0.9220  0.8183  0.8711  0.8588   \n",
              "nb                  Naive Bayes    0.8091  0.9099  0.7958  0.8167  0.8098   \n",
              "lr          Logistic Regression    0.8090  0.9346  0.7122  0.8338  0.7965   \n",
              "svm         SVM - Linear Kernel    0.7961  0.0000  0.7396  0.8187  0.7854   \n",
              "dt     Decision Tree Classifier    0.7832  0.7883  0.7480  0.7872  0.7788   \n",
              "ridge          Ridge Classifier    0.7431  0.0000  0.6083  0.7541  0.7172   \n",
              "\n",
              "        Kappa     MCC  TT (Sec)  \n",
              "knn    0.7430  0.7522     0.115  \n",
              "nb     0.6629  0.6658     0.017  \n",
              "lr     0.6242  0.6519     0.300  \n",
              "svm    0.6178  0.6415     0.062  \n",
              "dt     0.6013  0.6070     0.020  \n",
              "ridge  0.4792  0.5144     0.015  "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>AUC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Prec.</th>\n",
              "      <th>F1</th>\n",
              "      <th>Kappa</th>\n",
              "      <th>MCC</th>\n",
              "      <th>TT (Sec)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>rf</th>\n",
              "      <td>Random Forest Classifier</td>\n",
              "      <td>0.8679</td>\n",
              "      <td>0.9470</td>\n",
              "      <td>0.8246</td>\n",
              "      <td>0.8739</td>\n",
              "      <td>0.8654</td>\n",
              "      <td>0.7561</td>\n",
              "      <td>0.7622</td>\n",
              "      <td>0.518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>knn</th>\n",
              "      <td>K Neighbors Classifier</td>\n",
              "      <td>0.8620</td>\n",
              "      <td>0.9220</td>\n",
              "      <td>0.8183</td>\n",
              "      <td>0.8711</td>\n",
              "      <td>0.8588</td>\n",
              "      <td>0.7430</td>\n",
              "      <td>0.7522</td>\n",
              "      <td>0.115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nb</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>0.8091</td>\n",
              "      <td>0.9099</td>\n",
              "      <td>0.7958</td>\n",
              "      <td>0.8167</td>\n",
              "      <td>0.8098</td>\n",
              "      <td>0.6629</td>\n",
              "      <td>0.6658</td>\n",
              "      <td>0.017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lr</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.8090</td>\n",
              "      <td>0.9346</td>\n",
              "      <td>0.7122</td>\n",
              "      <td>0.8338</td>\n",
              "      <td>0.7965</td>\n",
              "      <td>0.6242</td>\n",
              "      <td>0.6519</td>\n",
              "      <td>0.300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>svm</th>\n",
              "      <td>SVM - Linear Kernel</td>\n",
              "      <td>0.7961</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.7396</td>\n",
              "      <td>0.8187</td>\n",
              "      <td>0.7854</td>\n",
              "      <td>0.6178</td>\n",
              "      <td>0.6415</td>\n",
              "      <td>0.062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dt</th>\n",
              "      <td>Decision Tree Classifier</td>\n",
              "      <td>0.7832</td>\n",
              "      <td>0.7883</td>\n",
              "      <td>0.7480</td>\n",
              "      <td>0.7872</td>\n",
              "      <td>0.7788</td>\n",
              "      <td>0.6013</td>\n",
              "      <td>0.6070</td>\n",
              "      <td>0.020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ridge</th>\n",
              "      <td>Ridge Classifier</td>\n",
              "      <td>0.7431</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.6083</td>\n",
              "      <td>0.7541</td>\n",
              "      <td>0.7172</td>\n",
              "      <td>0.4792</td>\n",
              "      <td>0.5144</td>\n",
              "      <td>0.015</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                          Model  Accuracy     AUC  Recall   Prec.      F1  \\\n",
              "rf     Random Forest Classifier    0.8679  0.9470  0.8246  0.8739  0.8654   \n",
              "knn      K Neighbors Classifier    0.8620  0.9220  0.8183  0.8711  0.8588   \n",
              "nb                  Naive Bayes    0.8091  0.9099  0.7958  0.8167  0.8098   \n",
              "lr          Logistic Regression    0.8090  0.9346  0.7122  0.8338  0.7965   \n",
              "svm         SVM - Linear Kernel    0.7961  0.0000  0.7396  0.8187  0.7854   \n",
              "dt     Decision Tree Classifier    0.7832  0.7883  0.7480  0.7872  0.7788   \n",
              "ridge          Ridge Classifier    0.7431  0.0000  0.6083  0.7541  0.7172   \n",
              "\n",
              "        Kappa     MCC  TT (Sec)  \n",
              "rf     0.7561  0.7622     0.518  \n",
              "knn    0.7430  0.7522     0.115  \n",
              "nb     0.6629  0.6658     0.017  \n",
              "lr     0.6242  0.6519     0.300  \n",
              "svm    0.6178  0.6415     0.062  \n",
              "dt     0.6013  0.6070     0.020  \n",
              "ridge  0.4792  0.5144     0.015  "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>AUC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Prec.</th>\n",
              "      <th>F1</th>\n",
              "      <th>Kappa</th>\n",
              "      <th>MCC</th>\n",
              "      <th>TT (Sec)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>rf</th>\n",
              "      <td>Random Forest Classifier</td>\n",
              "      <td>0.8679</td>\n",
              "      <td>0.9470</td>\n",
              "      <td>0.8246</td>\n",
              "      <td>0.8739</td>\n",
              "      <td>0.8654</td>\n",
              "      <td>0.7561</td>\n",
              "      <td>0.7622</td>\n",
              "      <td>0.518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>knn</th>\n",
              "      <td>K Neighbors Classifier</td>\n",
              "      <td>0.8620</td>\n",
              "      <td>0.9220</td>\n",
              "      <td>0.8183</td>\n",
              "      <td>0.8711</td>\n",
              "      <td>0.8588</td>\n",
              "      <td>0.7430</td>\n",
              "      <td>0.7522</td>\n",
              "      <td>0.115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>qda</th>\n",
              "      <td>Quadratic Discriminant Analysis</td>\n",
              "      <td>0.8329</td>\n",
              "      <td>0.9061</td>\n",
              "      <td>0.8255</td>\n",
              "      <td>0.8371</td>\n",
              "      <td>0.8324</td>\n",
              "      <td>0.7038</td>\n",
              "      <td>0.7063</td>\n",
              "      <td>0.018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nb</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>0.8091</td>\n",
              "      <td>0.9099</td>\n",
              "      <td>0.7958</td>\n",
              "      <td>0.8167</td>\n",
              "      <td>0.8098</td>\n",
              "      <td>0.6629</td>\n",
              "      <td>0.6658</td>\n",
              "      <td>0.017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lr</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.8090</td>\n",
              "      <td>0.9346</td>\n",
              "      <td>0.7122</td>\n",
              "      <td>0.8338</td>\n",
              "      <td>0.7965</td>\n",
              "      <td>0.6242</td>\n",
              "      <td>0.6519</td>\n",
              "      <td>0.300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>svm</th>\n",
              "      <td>SVM - Linear Kernel</td>\n",
              "      <td>0.7961</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.7396</td>\n",
              "      <td>0.8187</td>\n",
              "      <td>0.7854</td>\n",
              "      <td>0.6178</td>\n",
              "      <td>0.6415</td>\n",
              "      <td>0.062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dt</th>\n",
              "      <td>Decision Tree Classifier</td>\n",
              "      <td>0.7832</td>\n",
              "      <td>0.7883</td>\n",
              "      <td>0.7480</td>\n",
              "      <td>0.7872</td>\n",
              "      <td>0.7788</td>\n",
              "      <td>0.6013</td>\n",
              "      <td>0.6070</td>\n",
              "      <td>0.020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ridge</th>\n",
              "      <td>Ridge Classifier</td>\n",
              "      <td>0.7431</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.6083</td>\n",
              "      <td>0.7541</td>\n",
              "      <td>0.7172</td>\n",
              "      <td>0.4792</td>\n",
              "      <td>0.5144</td>\n",
              "      <td>0.015</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 Model  Accuracy     AUC  Recall   Prec.  \\\n",
              "rf            Random Forest Classifier    0.8679  0.9470  0.8246  0.8739   \n",
              "knn             K Neighbors Classifier    0.8620  0.9220  0.8183  0.8711   \n",
              "qda    Quadratic Discriminant Analysis    0.8329  0.9061  0.8255  0.8371   \n",
              "nb                         Naive Bayes    0.8091  0.9099  0.7958  0.8167   \n",
              "lr                 Logistic Regression    0.8090  0.9346  0.7122  0.8338   \n",
              "svm                SVM - Linear Kernel    0.7961  0.0000  0.7396  0.8187   \n",
              "dt            Decision Tree Classifier    0.7832  0.7883  0.7480  0.7872   \n",
              "ridge                 Ridge Classifier    0.7431  0.0000  0.6083  0.7541   \n",
              "\n",
              "           F1   Kappa     MCC  TT (Sec)  \n",
              "rf     0.8654  0.7561  0.7622     0.518  \n",
              "knn    0.8588  0.7430  0.7522     0.115  \n",
              "qda    0.8324  0.7038  0.7063     0.018  \n",
              "nb     0.8098  0.6629  0.6658     0.017  \n",
              "lr     0.7965  0.6242  0.6519     0.300  \n",
              "svm    0.7854  0.6178  0.6415     0.062  \n",
              "dt     0.7788  0.6013  0.6070     0.020  \n",
              "ridge  0.7172  0.4792  0.5144     0.015  "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>AUC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Prec.</th>\n",
              "      <th>F1</th>\n",
              "      <th>Kappa</th>\n",
              "      <th>MCC</th>\n",
              "      <th>TT (Sec)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>rf</th>\n",
              "      <td>Random Forest Classifier</td>\n",
              "      <td>0.8679</td>\n",
              "      <td>0.9470</td>\n",
              "      <td>0.8246</td>\n",
              "      <td>0.8739</td>\n",
              "      <td>0.8654</td>\n",
              "      <td>0.7561</td>\n",
              "      <td>0.7622</td>\n",
              "      <td>0.518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>knn</th>\n",
              "      <td>K Neighbors Classifier</td>\n",
              "      <td>0.8620</td>\n",
              "      <td>0.9220</td>\n",
              "      <td>0.8183</td>\n",
              "      <td>0.8711</td>\n",
              "      <td>0.8588</td>\n",
              "      <td>0.7430</td>\n",
              "      <td>0.7522</td>\n",
              "      <td>0.115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>qda</th>\n",
              "      <td>Quadratic Discriminant Analysis</td>\n",
              "      <td>0.8329</td>\n",
              "      <td>0.9061</td>\n",
              "      <td>0.8255</td>\n",
              "      <td>0.8371</td>\n",
              "      <td>0.8324</td>\n",
              "      <td>0.7038</td>\n",
              "      <td>0.7063</td>\n",
              "      <td>0.018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ada</th>\n",
              "      <td>Ada Boost Classifier</td>\n",
              "      <td>0.8275</td>\n",
              "      <td>0.8808</td>\n",
              "      <td>0.7400</td>\n",
              "      <td>0.8510</td>\n",
              "      <td>0.8158</td>\n",
              "      <td>0.6646</td>\n",
              "      <td>0.6894</td>\n",
              "      <td>0.123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nb</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>0.8091</td>\n",
              "      <td>0.9099</td>\n",
              "      <td>0.7958</td>\n",
              "      <td>0.8167</td>\n",
              "      <td>0.8098</td>\n",
              "      <td>0.6629</td>\n",
              "      <td>0.6658</td>\n",
              "      <td>0.017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lr</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.8090</td>\n",
              "      <td>0.9346</td>\n",
              "      <td>0.7122</td>\n",
              "      <td>0.8338</td>\n",
              "      <td>0.7965</td>\n",
              "      <td>0.6242</td>\n",
              "      <td>0.6519</td>\n",
              "      <td>0.300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>svm</th>\n",
              "      <td>SVM - Linear Kernel</td>\n",
              "      <td>0.7961</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.7396</td>\n",
              "      <td>0.8187</td>\n",
              "      <td>0.7854</td>\n",
              "      <td>0.6178</td>\n",
              "      <td>0.6415</td>\n",
              "      <td>0.062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dt</th>\n",
              "      <td>Decision Tree Classifier</td>\n",
              "      <td>0.7832</td>\n",
              "      <td>0.7883</td>\n",
              "      <td>0.7480</td>\n",
              "      <td>0.7872</td>\n",
              "      <td>0.7788</td>\n",
              "      <td>0.6013</td>\n",
              "      <td>0.6070</td>\n",
              "      <td>0.020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ridge</th>\n",
              "      <td>Ridge Classifier</td>\n",
              "      <td>0.7431</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.6083</td>\n",
              "      <td>0.7541</td>\n",
              "      <td>0.7172</td>\n",
              "      <td>0.4792</td>\n",
              "      <td>0.5144</td>\n",
              "      <td>0.015</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 Model  Accuracy     AUC  Recall   Prec.  \\\n",
              "rf            Random Forest Classifier    0.8679  0.9470  0.8246  0.8739   \n",
              "knn             K Neighbors Classifier    0.8620  0.9220  0.8183  0.8711   \n",
              "qda    Quadratic Discriminant Analysis    0.8329  0.9061  0.8255  0.8371   \n",
              "ada               Ada Boost Classifier    0.8275  0.8808  0.7400  0.8510   \n",
              "nb                         Naive Bayes    0.8091  0.9099  0.7958  0.8167   \n",
              "lr                 Logistic Regression    0.8090  0.9346  0.7122  0.8338   \n",
              "svm                SVM - Linear Kernel    0.7961  0.0000  0.7396  0.8187   \n",
              "dt            Decision Tree Classifier    0.7832  0.7883  0.7480  0.7872   \n",
              "ridge                 Ridge Classifier    0.7431  0.0000  0.6083  0.7541   \n",
              "\n",
              "           F1   Kappa     MCC  TT (Sec)  \n",
              "rf     0.8654  0.7561  0.7622     0.518  \n",
              "knn    0.8588  0.7430  0.7522     0.115  \n",
              "qda    0.8324  0.7038  0.7063     0.018  \n",
              "ada    0.8158  0.6646  0.6894     0.123  \n",
              "nb     0.8098  0.6629  0.6658     0.017  \n",
              "lr     0.7965  0.6242  0.6519     0.300  \n",
              "svm    0.7854  0.6178  0.6415     0.062  \n",
              "dt     0.7788  0.6013  0.6070     0.020  \n",
              "ridge  0.7172  0.4792  0.5144     0.015  "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>AUC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Prec.</th>\n",
              "      <th>F1</th>\n",
              "      <th>Kappa</th>\n",
              "      <th>MCC</th>\n",
              "      <th>TT (Sec)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>rf</th>\n",
              "      <td>Random Forest Classifier</td>\n",
              "      <td>0.8679</td>\n",
              "      <td>0.9470</td>\n",
              "      <td>0.8246</td>\n",
              "      <td>0.8739</td>\n",
              "      <td>0.8654</td>\n",
              "      <td>0.7561</td>\n",
              "      <td>0.7622</td>\n",
              "      <td>0.518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>knn</th>\n",
              "      <td>K Neighbors Classifier</td>\n",
              "      <td>0.8620</td>\n",
              "      <td>0.9220</td>\n",
              "      <td>0.8183</td>\n",
              "      <td>0.8711</td>\n",
              "      <td>0.8588</td>\n",
              "      <td>0.7430</td>\n",
              "      <td>0.7522</td>\n",
              "      <td>0.115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gbc</th>\n",
              "      <td>Gradient Boosting Classifier</td>\n",
              "      <td>0.8566</td>\n",
              "      <td>0.9441</td>\n",
              "      <td>0.8088</td>\n",
              "      <td>0.8688</td>\n",
              "      <td>0.8511</td>\n",
              "      <td>0.7324</td>\n",
              "      <td>0.7465</td>\n",
              "      <td>0.553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>qda</th>\n",
              "      <td>Quadratic Discriminant Analysis</td>\n",
              "      <td>0.8329</td>\n",
              "      <td>0.9061</td>\n",
              "      <td>0.8255</td>\n",
              "      <td>0.8371</td>\n",
              "      <td>0.8324</td>\n",
              "      <td>0.7038</td>\n",
              "      <td>0.7063</td>\n",
              "      <td>0.018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ada</th>\n",
              "      <td>Ada Boost Classifier</td>\n",
              "      <td>0.8275</td>\n",
              "      <td>0.8808</td>\n",
              "      <td>0.7400</td>\n",
              "      <td>0.8510</td>\n",
              "      <td>0.8158</td>\n",
              "      <td>0.6646</td>\n",
              "      <td>0.6894</td>\n",
              "      <td>0.123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nb</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>0.8091</td>\n",
              "      <td>0.9099</td>\n",
              "      <td>0.7958</td>\n",
              "      <td>0.8167</td>\n",
              "      <td>0.8098</td>\n",
              "      <td>0.6629</td>\n",
              "      <td>0.6658</td>\n",
              "      <td>0.017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lr</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.8090</td>\n",
              "      <td>0.9346</td>\n",
              "      <td>0.7122</td>\n",
              "      <td>0.8338</td>\n",
              "      <td>0.7965</td>\n",
              "      <td>0.6242</td>\n",
              "      <td>0.6519</td>\n",
              "      <td>0.300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>svm</th>\n",
              "      <td>SVM - Linear Kernel</td>\n",
              "      <td>0.7961</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.7396</td>\n",
              "      <td>0.8187</td>\n",
              "      <td>0.7854</td>\n",
              "      <td>0.6178</td>\n",
              "      <td>0.6415</td>\n",
              "      <td>0.062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dt</th>\n",
              "      <td>Decision Tree Classifier</td>\n",
              "      <td>0.7832</td>\n",
              "      <td>0.7883</td>\n",
              "      <td>0.7480</td>\n",
              "      <td>0.7872</td>\n",
              "      <td>0.7788</td>\n",
              "      <td>0.6013</td>\n",
              "      <td>0.6070</td>\n",
              "      <td>0.020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ridge</th>\n",
              "      <td>Ridge Classifier</td>\n",
              "      <td>0.7431</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.6083</td>\n",
              "      <td>0.7541</td>\n",
              "      <td>0.7172</td>\n",
              "      <td>0.4792</td>\n",
              "      <td>0.5144</td>\n",
              "      <td>0.015</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 Model  Accuracy     AUC  Recall   Prec.  \\\n",
              "rf            Random Forest Classifier    0.8679  0.9470  0.8246  0.8739   \n",
              "knn             K Neighbors Classifier    0.8620  0.9220  0.8183  0.8711   \n",
              "gbc       Gradient Boosting Classifier    0.8566  0.9441  0.8088  0.8688   \n",
              "qda    Quadratic Discriminant Analysis    0.8329  0.9061  0.8255  0.8371   \n",
              "ada               Ada Boost Classifier    0.8275  0.8808  0.7400  0.8510   \n",
              "nb                         Naive Bayes    0.8091  0.9099  0.7958  0.8167   \n",
              "lr                 Logistic Regression    0.8090  0.9346  0.7122  0.8338   \n",
              "svm                SVM - Linear Kernel    0.7961  0.0000  0.7396  0.8187   \n",
              "dt            Decision Tree Classifier    0.7832  0.7883  0.7480  0.7872   \n",
              "ridge                 Ridge Classifier    0.7431  0.0000  0.6083  0.7541   \n",
              "\n",
              "           F1   Kappa     MCC  TT (Sec)  \n",
              "rf     0.8654  0.7561  0.7622     0.518  \n",
              "knn    0.8588  0.7430  0.7522     0.115  \n",
              "gbc    0.8511  0.7324  0.7465     0.553  \n",
              "qda    0.8324  0.7038  0.7063     0.018  \n",
              "ada    0.8158  0.6646  0.6894     0.123  \n",
              "nb     0.8098  0.6629  0.6658     0.017  \n",
              "lr     0.7965  0.6242  0.6519     0.300  \n",
              "svm    0.7854  0.6178  0.6415     0.062  \n",
              "dt     0.7788  0.6013  0.6070     0.020  \n",
              "ridge  0.7172  0.4792  0.5144     0.015  "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>AUC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Prec.</th>\n",
              "      <th>F1</th>\n",
              "      <th>Kappa</th>\n",
              "      <th>MCC</th>\n",
              "      <th>TT (Sec)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>rf</th>\n",
              "      <td>Random Forest Classifier</td>\n",
              "      <td>0.8679</td>\n",
              "      <td>0.9470</td>\n",
              "      <td>0.8246</td>\n",
              "      <td>0.8739</td>\n",
              "      <td>0.8654</td>\n",
              "      <td>0.7561</td>\n",
              "      <td>0.7622</td>\n",
              "      <td>0.518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>knn</th>\n",
              "      <td>K Neighbors Classifier</td>\n",
              "      <td>0.8620</td>\n",
              "      <td>0.9220</td>\n",
              "      <td>0.8183</td>\n",
              "      <td>0.8711</td>\n",
              "      <td>0.8588</td>\n",
              "      <td>0.7430</td>\n",
              "      <td>0.7522</td>\n",
              "      <td>0.115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gbc</th>\n",
              "      <td>Gradient Boosting Classifier</td>\n",
              "      <td>0.8566</td>\n",
              "      <td>0.9441</td>\n",
              "      <td>0.8088</td>\n",
              "      <td>0.8688</td>\n",
              "      <td>0.8511</td>\n",
              "      <td>0.7324</td>\n",
              "      <td>0.7465</td>\n",
              "      <td>0.553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>qda</th>\n",
              "      <td>Quadratic Discriminant Analysis</td>\n",
              "      <td>0.8329</td>\n",
              "      <td>0.9061</td>\n",
              "      <td>0.8255</td>\n",
              "      <td>0.8371</td>\n",
              "      <td>0.8324</td>\n",
              "      <td>0.7038</td>\n",
              "      <td>0.7063</td>\n",
              "      <td>0.018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lda</th>\n",
              "      <td>Linear Discriminant Analysis</td>\n",
              "      <td>0.8328</td>\n",
              "      <td>0.9350</td>\n",
              "      <td>0.7669</td>\n",
              "      <td>0.8493</td>\n",
              "      <td>0.8252</td>\n",
              "      <td>0.6795</td>\n",
              "      <td>0.6970</td>\n",
              "      <td>0.018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ada</th>\n",
              "      <td>Ada Boost Classifier</td>\n",
              "      <td>0.8275</td>\n",
              "      <td>0.8808</td>\n",
              "      <td>0.7400</td>\n",
              "      <td>0.8510</td>\n",
              "      <td>0.8158</td>\n",
              "      <td>0.6646</td>\n",
              "      <td>0.6894</td>\n",
              "      <td>0.123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nb</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>0.8091</td>\n",
              "      <td>0.9099</td>\n",
              "      <td>0.7958</td>\n",
              "      <td>0.8167</td>\n",
              "      <td>0.8098</td>\n",
              "      <td>0.6629</td>\n",
              "      <td>0.6658</td>\n",
              "      <td>0.017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lr</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.8090</td>\n",
              "      <td>0.9346</td>\n",
              "      <td>0.7122</td>\n",
              "      <td>0.8338</td>\n",
              "      <td>0.7965</td>\n",
              "      <td>0.6242</td>\n",
              "      <td>0.6519</td>\n",
              "      <td>0.300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>svm</th>\n",
              "      <td>SVM - Linear Kernel</td>\n",
              "      <td>0.7961</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.7396</td>\n",
              "      <td>0.8187</td>\n",
              "      <td>0.7854</td>\n",
              "      <td>0.6178</td>\n",
              "      <td>0.6415</td>\n",
              "      <td>0.062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dt</th>\n",
              "      <td>Decision Tree Classifier</td>\n",
              "      <td>0.7832</td>\n",
              "      <td>0.7883</td>\n",
              "      <td>0.7480</td>\n",
              "      <td>0.7872</td>\n",
              "      <td>0.7788</td>\n",
              "      <td>0.6013</td>\n",
              "      <td>0.6070</td>\n",
              "      <td>0.020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ridge</th>\n",
              "      <td>Ridge Classifier</td>\n",
              "      <td>0.7431</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.6083</td>\n",
              "      <td>0.7541</td>\n",
              "      <td>0.7172</td>\n",
              "      <td>0.4792</td>\n",
              "      <td>0.5144</td>\n",
              "      <td>0.015</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 Model  Accuracy     AUC  Recall   Prec.  \\\n",
              "rf            Random Forest Classifier    0.8679  0.9470  0.8246  0.8739   \n",
              "knn             K Neighbors Classifier    0.8620  0.9220  0.8183  0.8711   \n",
              "gbc       Gradient Boosting Classifier    0.8566  0.9441  0.8088  0.8688   \n",
              "qda    Quadratic Discriminant Analysis    0.8329  0.9061  0.8255  0.8371   \n",
              "lda       Linear Discriminant Analysis    0.8328  0.9350  0.7669  0.8493   \n",
              "ada               Ada Boost Classifier    0.8275  0.8808  0.7400  0.8510   \n",
              "nb                         Naive Bayes    0.8091  0.9099  0.7958  0.8167   \n",
              "lr                 Logistic Regression    0.8090  0.9346  0.7122  0.8338   \n",
              "svm                SVM - Linear Kernel    0.7961  0.0000  0.7396  0.8187   \n",
              "dt            Decision Tree Classifier    0.7832  0.7883  0.7480  0.7872   \n",
              "ridge                 Ridge Classifier    0.7431  0.0000  0.6083  0.7541   \n",
              "\n",
              "           F1   Kappa     MCC  TT (Sec)  \n",
              "rf     0.8654  0.7561  0.7622     0.518  \n",
              "knn    0.8588  0.7430  0.7522     0.115  \n",
              "gbc    0.8511  0.7324  0.7465     0.553  \n",
              "qda    0.8324  0.7038  0.7063     0.018  \n",
              "lda    0.8252  0.6795  0.6970     0.018  \n",
              "ada    0.8158  0.6646  0.6894     0.123  \n",
              "nb     0.8098  0.6629  0.6658     0.017  \n",
              "lr     0.7965  0.6242  0.6519     0.300  \n",
              "svm    0.7854  0.6178  0.6415     0.062  \n",
              "dt     0.7788  0.6013  0.6070     0.020  \n",
              "ridge  0.7172  0.4792  0.5144     0.015  "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>AUC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Prec.</th>\n",
              "      <th>F1</th>\n",
              "      <th>Kappa</th>\n",
              "      <th>MCC</th>\n",
              "      <th>TT (Sec)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>et</th>\n",
              "      <td>Extra Trees Classifier</td>\n",
              "      <td>0.8823</td>\n",
              "      <td>0.9580</td>\n",
              "      <td>0.8333</td>\n",
              "      <td>0.8893</td>\n",
              "      <td>0.8787</td>\n",
              "      <td>0.7791</td>\n",
              "      <td>0.7876</td>\n",
              "      <td>0.465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rf</th>\n",
              "      <td>Random Forest Classifier</td>\n",
              "      <td>0.8679</td>\n",
              "      <td>0.9470</td>\n",
              "      <td>0.8246</td>\n",
              "      <td>0.8739</td>\n",
              "      <td>0.8654</td>\n",
              "      <td>0.7561</td>\n",
              "      <td>0.7622</td>\n",
              "      <td>0.518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>knn</th>\n",
              "      <td>K Neighbors Classifier</td>\n",
              "      <td>0.8620</td>\n",
              "      <td>0.9220</td>\n",
              "      <td>0.8183</td>\n",
              "      <td>0.8711</td>\n",
              "      <td>0.8588</td>\n",
              "      <td>0.7430</td>\n",
              "      <td>0.7522</td>\n",
              "      <td>0.115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gbc</th>\n",
              "      <td>Gradient Boosting Classifier</td>\n",
              "      <td>0.8566</td>\n",
              "      <td>0.9441</td>\n",
              "      <td>0.8088</td>\n",
              "      <td>0.8688</td>\n",
              "      <td>0.8511</td>\n",
              "      <td>0.7324</td>\n",
              "      <td>0.7465</td>\n",
              "      <td>0.553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>qda</th>\n",
              "      <td>Quadratic Discriminant Analysis</td>\n",
              "      <td>0.8329</td>\n",
              "      <td>0.9061</td>\n",
              "      <td>0.8255</td>\n",
              "      <td>0.8371</td>\n",
              "      <td>0.8324</td>\n",
              "      <td>0.7038</td>\n",
              "      <td>0.7063</td>\n",
              "      <td>0.018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lda</th>\n",
              "      <td>Linear Discriminant Analysis</td>\n",
              "      <td>0.8328</td>\n",
              "      <td>0.9350</td>\n",
              "      <td>0.7669</td>\n",
              "      <td>0.8493</td>\n",
              "      <td>0.8252</td>\n",
              "      <td>0.6795</td>\n",
              "      <td>0.6970</td>\n",
              "      <td>0.018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ada</th>\n",
              "      <td>Ada Boost Classifier</td>\n",
              "      <td>0.8275</td>\n",
              "      <td>0.8808</td>\n",
              "      <td>0.7400</td>\n",
              "      <td>0.8510</td>\n",
              "      <td>0.8158</td>\n",
              "      <td>0.6646</td>\n",
              "      <td>0.6894</td>\n",
              "      <td>0.123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nb</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>0.8091</td>\n",
              "      <td>0.9099</td>\n",
              "      <td>0.7958</td>\n",
              "      <td>0.8167</td>\n",
              "      <td>0.8098</td>\n",
              "      <td>0.6629</td>\n",
              "      <td>0.6658</td>\n",
              "      <td>0.017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lr</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.8090</td>\n",
              "      <td>0.9346</td>\n",
              "      <td>0.7122</td>\n",
              "      <td>0.8338</td>\n",
              "      <td>0.7965</td>\n",
              "      <td>0.6242</td>\n",
              "      <td>0.6519</td>\n",
              "      <td>0.300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>svm</th>\n",
              "      <td>SVM - Linear Kernel</td>\n",
              "      <td>0.7961</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.7396</td>\n",
              "      <td>0.8187</td>\n",
              "      <td>0.7854</td>\n",
              "      <td>0.6178</td>\n",
              "      <td>0.6415</td>\n",
              "      <td>0.062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dt</th>\n",
              "      <td>Decision Tree Classifier</td>\n",
              "      <td>0.7832</td>\n",
              "      <td>0.7883</td>\n",
              "      <td>0.7480</td>\n",
              "      <td>0.7872</td>\n",
              "      <td>0.7788</td>\n",
              "      <td>0.6013</td>\n",
              "      <td>0.6070</td>\n",
              "      <td>0.020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ridge</th>\n",
              "      <td>Ridge Classifier</td>\n",
              "      <td>0.7431</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.6083</td>\n",
              "      <td>0.7541</td>\n",
              "      <td>0.7172</td>\n",
              "      <td>0.4792</td>\n",
              "      <td>0.5144</td>\n",
              "      <td>0.015</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                 Model  Accuracy     AUC  Recall   Prec.  \\\n",
              "et              Extra Trees Classifier    0.8823  0.9580  0.8333  0.8893   \n",
              "rf            Random Forest Classifier    0.8679  0.9470  0.8246  0.8739   \n",
              "knn             K Neighbors Classifier    0.8620  0.9220  0.8183  0.8711   \n",
              "gbc       Gradient Boosting Classifier    0.8566  0.9441  0.8088  0.8688   \n",
              "qda    Quadratic Discriminant Analysis    0.8329  0.9061  0.8255  0.8371   \n",
              "lda       Linear Discriminant Analysis    0.8328  0.9350  0.7669  0.8493   \n",
              "ada               Ada Boost Classifier    0.8275  0.8808  0.7400  0.8510   \n",
              "nb                         Naive Bayes    0.8091  0.9099  0.7958  0.8167   \n",
              "lr                 Logistic Regression    0.8090  0.9346  0.7122  0.8338   \n",
              "svm                SVM - Linear Kernel    0.7961  0.0000  0.7396  0.8187   \n",
              "dt            Decision Tree Classifier    0.7832  0.7883  0.7480  0.7872   \n",
              "ridge                 Ridge Classifier    0.7431  0.0000  0.6083  0.7541   \n",
              "\n",
              "           F1   Kappa     MCC  TT (Sec)  \n",
              "et     0.8787  0.7791  0.7876     0.465  \n",
              "rf     0.8654  0.7561  0.7622     0.518  \n",
              "knn    0.8588  0.7430  0.7522     0.115  \n",
              "gbc    0.8511  0.7324  0.7465     0.553  \n",
              "qda    0.8324  0.7038  0.7063     0.018  \n",
              "lda    0.8252  0.6795  0.6970     0.018  \n",
              "ada    0.8158  0.6646  0.6894     0.123  \n",
              "nb     0.8098  0.6629  0.6658     0.017  \n",
              "lr     0.7965  0.6242  0.6519     0.300  \n",
              "svm    0.7854  0.6178  0.6415     0.062  \n",
              "dt     0.7788  0.6013  0.6070     0.020  \n",
              "ridge  0.7172  0.4792  0.5144     0.015  "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>AUC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Prec.</th>\n",
              "      <th>F1</th>\n",
              "      <th>Kappa</th>\n",
              "      <th>MCC</th>\n",
              "      <th>TT (Sec)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>et</th>\n",
              "      <td>Extra Trees Classifier</td>\n",
              "      <td>0.8823</td>\n",
              "      <td>0.9580</td>\n",
              "      <td>0.8333</td>\n",
              "      <td>0.8893</td>\n",
              "      <td>0.8787</td>\n",
              "      <td>0.7791</td>\n",
              "      <td>0.7876</td>\n",
              "      <td>0.465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rf</th>\n",
              "      <td>Random Forest Classifier</td>\n",
              "      <td>0.8679</td>\n",
              "      <td>0.9470</td>\n",
              "      <td>0.8246</td>\n",
              "      <td>0.8739</td>\n",
              "      <td>0.8654</td>\n",
              "      <td>0.7561</td>\n",
              "      <td>0.7622</td>\n",
              "      <td>0.518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lightgbm</th>\n",
              "      <td>Light Gradient Boosting Machine</td>\n",
              "      <td>0.8676</td>\n",
              "      <td>0.9554</td>\n",
              "      <td>0.8255</td>\n",
              "      <td>0.8731</td>\n",
              "      <td>0.8648</td>\n",
              "      <td>0.7554</td>\n",
              "      <td>0.7618</td>\n",
              "      <td>0.232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>knn</th>\n",
              "      <td>K Neighbors Classifier</td>\n",
              "      <td>0.8620</td>\n",
              "      <td>0.9220</td>\n",
              "      <td>0.8183</td>\n",
              "      <td>0.8711</td>\n",
              "      <td>0.8588</td>\n",
              "      <td>0.7430</td>\n",
              "      <td>0.7522</td>\n",
              "      <td>0.115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gbc</th>\n",
              "      <td>Gradient Boosting Classifier</td>\n",
              "      <td>0.8566</td>\n",
              "      <td>0.9441</td>\n",
              "      <td>0.8088</td>\n",
              "      <td>0.8688</td>\n",
              "      <td>0.8511</td>\n",
              "      <td>0.7324</td>\n",
              "      <td>0.7465</td>\n",
              "      <td>0.553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>qda</th>\n",
              "      <td>Quadratic Discriminant Analysis</td>\n",
              "      <td>0.8329</td>\n",
              "      <td>0.9061</td>\n",
              "      <td>0.8255</td>\n",
              "      <td>0.8371</td>\n",
              "      <td>0.8324</td>\n",
              "      <td>0.7038</td>\n",
              "      <td>0.7063</td>\n",
              "      <td>0.018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lda</th>\n",
              "      <td>Linear Discriminant Analysis</td>\n",
              "      <td>0.8328</td>\n",
              "      <td>0.9350</td>\n",
              "      <td>0.7669</td>\n",
              "      <td>0.8493</td>\n",
              "      <td>0.8252</td>\n",
              "      <td>0.6795</td>\n",
              "      <td>0.6970</td>\n",
              "      <td>0.018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ada</th>\n",
              "      <td>Ada Boost Classifier</td>\n",
              "      <td>0.8275</td>\n",
              "      <td>0.8808</td>\n",
              "      <td>0.7400</td>\n",
              "      <td>0.8510</td>\n",
              "      <td>0.8158</td>\n",
              "      <td>0.6646</td>\n",
              "      <td>0.6894</td>\n",
              "      <td>0.123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nb</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>0.8091</td>\n",
              "      <td>0.9099</td>\n",
              "      <td>0.7958</td>\n",
              "      <td>0.8167</td>\n",
              "      <td>0.8098</td>\n",
              "      <td>0.6629</td>\n",
              "      <td>0.6658</td>\n",
              "      <td>0.017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lr</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.8090</td>\n",
              "      <td>0.9346</td>\n",
              "      <td>0.7122</td>\n",
              "      <td>0.8338</td>\n",
              "      <td>0.7965</td>\n",
              "      <td>0.6242</td>\n",
              "      <td>0.6519</td>\n",
              "      <td>0.300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>svm</th>\n",
              "      <td>SVM - Linear Kernel</td>\n",
              "      <td>0.7961</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.7396</td>\n",
              "      <td>0.8187</td>\n",
              "      <td>0.7854</td>\n",
              "      <td>0.6178</td>\n",
              "      <td>0.6415</td>\n",
              "      <td>0.062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dt</th>\n",
              "      <td>Decision Tree Classifier</td>\n",
              "      <td>0.7832</td>\n",
              "      <td>0.7883</td>\n",
              "      <td>0.7480</td>\n",
              "      <td>0.7872</td>\n",
              "      <td>0.7788</td>\n",
              "      <td>0.6013</td>\n",
              "      <td>0.6070</td>\n",
              "      <td>0.020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ridge</th>\n",
              "      <td>Ridge Classifier</td>\n",
              "      <td>0.7431</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.6083</td>\n",
              "      <td>0.7541</td>\n",
              "      <td>0.7172</td>\n",
              "      <td>0.4792</td>\n",
              "      <td>0.5144</td>\n",
              "      <td>0.015</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
              "et                 Extra Trees Classifier    0.8823  0.9580  0.8333  0.8893   \n",
              "rf               Random Forest Classifier    0.8679  0.9470  0.8246  0.8739   \n",
              "lightgbm  Light Gradient Boosting Machine    0.8676  0.9554  0.8255  0.8731   \n",
              "knn                K Neighbors Classifier    0.8620  0.9220  0.8183  0.8711   \n",
              "gbc          Gradient Boosting Classifier    0.8566  0.9441  0.8088  0.8688   \n",
              "qda       Quadratic Discriminant Analysis    0.8329  0.9061  0.8255  0.8371   \n",
              "lda          Linear Discriminant Analysis    0.8328  0.9350  0.7669  0.8493   \n",
              "ada                  Ada Boost Classifier    0.8275  0.8808  0.7400  0.8510   \n",
              "nb                            Naive Bayes    0.8091  0.9099  0.7958  0.8167   \n",
              "lr                    Logistic Regression    0.8090  0.9346  0.7122  0.8338   \n",
              "svm                   SVM - Linear Kernel    0.7961  0.0000  0.7396  0.8187   \n",
              "dt               Decision Tree Classifier    0.7832  0.7883  0.7480  0.7872   \n",
              "ridge                    Ridge Classifier    0.7431  0.0000  0.6083  0.7541   \n",
              "\n",
              "              F1   Kappa     MCC  TT (Sec)  \n",
              "et        0.8787  0.7791  0.7876     0.465  \n",
              "rf        0.8654  0.7561  0.7622     0.518  \n",
              "lightgbm  0.8648  0.7554  0.7618     0.232  \n",
              "knn       0.8588  0.7430  0.7522     0.115  \n",
              "gbc       0.8511  0.7324  0.7465     0.553  \n",
              "qda       0.8324  0.7038  0.7063     0.018  \n",
              "lda       0.8252  0.6795  0.6970     0.018  \n",
              "ada       0.8158  0.6646  0.6894     0.123  \n",
              "nb        0.8098  0.6629  0.6658     0.017  \n",
              "lr        0.7965  0.6242  0.6519     0.300  \n",
              "svm       0.7854  0.6178  0.6415     0.062  \n",
              "dt        0.7788  0.6013  0.6070     0.020  \n",
              "ridge     0.7172  0.4792  0.5144     0.015  "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Model</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>AUC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Prec.</th>\n",
              "      <th>F1</th>\n",
              "      <th>Kappa</th>\n",
              "      <th>MCC</th>\n",
              "      <th>TT (Sec)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>et</th>\n",
              "      <td>Extra Trees Classifier</td>\n",
              "      <td>0.8823</td>\n",
              "      <td>0.9580</td>\n",
              "      <td>0.8333</td>\n",
              "      <td>0.8893</td>\n",
              "      <td>0.8787</td>\n",
              "      <td>0.7791</td>\n",
              "      <td>0.7876</td>\n",
              "      <td>0.465</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rf</th>\n",
              "      <td>Random Forest Classifier</td>\n",
              "      <td>0.8679</td>\n",
              "      <td>0.9470</td>\n",
              "      <td>0.8246</td>\n",
              "      <td>0.8739</td>\n",
              "      <td>0.8654</td>\n",
              "      <td>0.7561</td>\n",
              "      <td>0.7622</td>\n",
              "      <td>0.518</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lightgbm</th>\n",
              "      <td>Light Gradient Boosting Machine</td>\n",
              "      <td>0.8676</td>\n",
              "      <td>0.9554</td>\n",
              "      <td>0.8255</td>\n",
              "      <td>0.8731</td>\n",
              "      <td>0.8648</td>\n",
              "      <td>0.7554</td>\n",
              "      <td>0.7618</td>\n",
              "      <td>0.232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>knn</th>\n",
              "      <td>K Neighbors Classifier</td>\n",
              "      <td>0.8620</td>\n",
              "      <td>0.9220</td>\n",
              "      <td>0.8183</td>\n",
              "      <td>0.8711</td>\n",
              "      <td>0.8588</td>\n",
              "      <td>0.7430</td>\n",
              "      <td>0.7522</td>\n",
              "      <td>0.115</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gbc</th>\n",
              "      <td>Gradient Boosting Classifier</td>\n",
              "      <td>0.8566</td>\n",
              "      <td>0.9441</td>\n",
              "      <td>0.8088</td>\n",
              "      <td>0.8688</td>\n",
              "      <td>0.8511</td>\n",
              "      <td>0.7324</td>\n",
              "      <td>0.7465</td>\n",
              "      <td>0.553</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>qda</th>\n",
              "      <td>Quadratic Discriminant Analysis</td>\n",
              "      <td>0.8329</td>\n",
              "      <td>0.9061</td>\n",
              "      <td>0.8255</td>\n",
              "      <td>0.8371</td>\n",
              "      <td>0.8324</td>\n",
              "      <td>0.7038</td>\n",
              "      <td>0.7063</td>\n",
              "      <td>0.018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lda</th>\n",
              "      <td>Linear Discriminant Analysis</td>\n",
              "      <td>0.8328</td>\n",
              "      <td>0.9350</td>\n",
              "      <td>0.7669</td>\n",
              "      <td>0.8493</td>\n",
              "      <td>0.8252</td>\n",
              "      <td>0.6795</td>\n",
              "      <td>0.6970</td>\n",
              "      <td>0.018</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ada</th>\n",
              "      <td>Ada Boost Classifier</td>\n",
              "      <td>0.8275</td>\n",
              "      <td>0.8808</td>\n",
              "      <td>0.7400</td>\n",
              "      <td>0.8510</td>\n",
              "      <td>0.8158</td>\n",
              "      <td>0.6646</td>\n",
              "      <td>0.6894</td>\n",
              "      <td>0.123</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>nb</th>\n",
              "      <td>Naive Bayes</td>\n",
              "      <td>0.8091</td>\n",
              "      <td>0.9099</td>\n",
              "      <td>0.7958</td>\n",
              "      <td>0.8167</td>\n",
              "      <td>0.8098</td>\n",
              "      <td>0.6629</td>\n",
              "      <td>0.6658</td>\n",
              "      <td>0.017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>lr</th>\n",
              "      <td>Logistic Regression</td>\n",
              "      <td>0.8090</td>\n",
              "      <td>0.9346</td>\n",
              "      <td>0.7122</td>\n",
              "      <td>0.8338</td>\n",
              "      <td>0.7965</td>\n",
              "      <td>0.6242</td>\n",
              "      <td>0.6519</td>\n",
              "      <td>0.300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>svm</th>\n",
              "      <td>SVM - Linear Kernel</td>\n",
              "      <td>0.7961</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.7396</td>\n",
              "      <td>0.8187</td>\n",
              "      <td>0.7854</td>\n",
              "      <td>0.6178</td>\n",
              "      <td>0.6415</td>\n",
              "      <td>0.062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>dt</th>\n",
              "      <td>Decision Tree Classifier</td>\n",
              "      <td>0.7832</td>\n",
              "      <td>0.7883</td>\n",
              "      <td>0.7480</td>\n",
              "      <td>0.7872</td>\n",
              "      <td>0.7788</td>\n",
              "      <td>0.6013</td>\n",
              "      <td>0.6070</td>\n",
              "      <td>0.020</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ridge</th>\n",
              "      <td>Ridge Classifier</td>\n",
              "      <td>0.7431</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.6083</td>\n",
              "      <td>0.7541</td>\n",
              "      <td>0.7172</td>\n",
              "      <td>0.4792</td>\n",
              "      <td>0.5144</td>\n",
              "      <td>0.015</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                    Model  Accuracy     AUC  Recall   Prec.  \\\n",
              "et                 Extra Trees Classifier    0.8823  0.9580  0.8333  0.8893   \n",
              "rf               Random Forest Classifier    0.8679  0.9470  0.8246  0.8739   \n",
              "lightgbm  Light Gradient Boosting Machine    0.8676  0.9554  0.8255  0.8731   \n",
              "knn                K Neighbors Classifier    0.8620  0.9220  0.8183  0.8711   \n",
              "gbc          Gradient Boosting Classifier    0.8566  0.9441  0.8088  0.8688   \n",
              "qda       Quadratic Discriminant Analysis    0.8329  0.9061  0.8255  0.8371   \n",
              "lda          Linear Discriminant Analysis    0.8328  0.9350  0.7669  0.8493   \n",
              "ada                  Ada Boost Classifier    0.8275  0.8808  0.7400  0.8510   \n",
              "nb                            Naive Bayes    0.8091  0.9099  0.7958  0.8167   \n",
              "lr                    Logistic Regression    0.8090  0.9346  0.7122  0.8338   \n",
              "svm                   SVM - Linear Kernel    0.7961  0.0000  0.7396  0.8187   \n",
              "dt               Decision Tree Classifier    0.7832  0.7883  0.7480  0.7872   \n",
              "ridge                    Ridge Classifier    0.7431  0.0000  0.6083  0.7541   \n",
              "\n",
              "              F1   Kappa     MCC  TT (Sec)  \n",
              "et        0.8787  0.7791  0.7876     0.465  \n",
              "rf        0.8654  0.7561  0.7622     0.518  \n",
              "lightgbm  0.8648  0.7554  0.7618     0.232  \n",
              "knn       0.8588  0.7430  0.7522     0.115  \n",
              "gbc       0.8511  0.7324  0.7465     0.553  \n",
              "qda       0.8324  0.7038  0.7063     0.018  \n",
              "lda       0.8252  0.6795  0.6970     0.018  \n",
              "ada       0.8158  0.6646  0.6894     0.123  \n",
              "nb        0.8098  0.6629  0.6658     0.017  \n",
              "lr        0.7965  0.6242  0.6519     0.300  \n",
              "svm       0.7854  0.6178  0.6415     0.062  \n",
              "dt        0.7788  0.6013  0.6070     0.020  \n",
              "ridge     0.7172  0.4792  0.5144     0.015  "
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blddvVaRTHRJ"
      },
      "source": [
        "Após uma série de testes, concluímos que o melhor modelo é o ExtraTreesClassifier, que ficou com uma acurácia média de 87.5%,então vamos usá-lo:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iymZXsBZ9kUv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        },
        "outputId": "ffdf10e5-3665-426b-e42d-c9207de4747d"
      },
      "source": [
        "best_model = tune_model(ExtraTreesClassifier(), n_iter=200)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 10 folds for each of 200 candidates, totalling 2000 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed:   13.6s\n",
            "[Parallel(n_jobs=-1)]: Done 198 tasks      | elapsed:   47.9s\n",
            "[Parallel(n_jobs=-1)]: Done 456 tasks      | elapsed:  1.9min\n",
            "[Parallel(n_jobs=-1)]: Done 806 tasks      | elapsed:  3.4min\n",
            "[Parallel(n_jobs=-1)]: Done 1256 tasks      | elapsed:  5.3min\n",
            "[Parallel(n_jobs=-1)]: Done 1806 tasks      | elapsed:  7.6min\n",
            "[Parallel(n_jobs=-1)]: Done 2000 out of 2000 | elapsed:  8.5min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>AUC</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Prec.</th>\n",
              "      <th>F1</th>\n",
              "      <th>Kappa</th>\n",
              "      <th>MCC</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.9636</td>\n",
              "      <td>0.9958</td>\n",
              "      <td>0.9674</td>\n",
              "      <td>0.9636</td>\n",
              "      <td>0.9636</td>\n",
              "      <td>0.9357</td>\n",
              "      <td>0.9357</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.8909</td>\n",
              "      <td>0.9637</td>\n",
              "      <td>0.8826</td>\n",
              "      <td>0.8943</td>\n",
              "      <td>0.8918</td>\n",
              "      <td>0.8065</td>\n",
              "      <td>0.8069</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.8182</td>\n",
              "      <td>0.9372</td>\n",
              "      <td>0.8250</td>\n",
              "      <td>0.8134</td>\n",
              "      <td>0.8144</td>\n",
              "      <td>0.6722</td>\n",
              "      <td>0.6740</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.8545</td>\n",
              "      <td>0.9567</td>\n",
              "      <td>0.8264</td>\n",
              "      <td>0.8576</td>\n",
              "      <td>0.8511</td>\n",
              "      <td>0.7312</td>\n",
              "      <td>0.7382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.8909</td>\n",
              "      <td>0.9625</td>\n",
              "      <td>0.8083</td>\n",
              "      <td>0.9081</td>\n",
              "      <td>0.8863</td>\n",
              "      <td>0.7923</td>\n",
              "      <td>0.8098</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.9074</td>\n",
              "      <td>0.9673</td>\n",
              "      <td>0.8499</td>\n",
              "      <td>0.9124</td>\n",
              "      <td>0.9054</td>\n",
              "      <td>0.8259</td>\n",
              "      <td>0.8306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0.8519</td>\n",
              "      <td>0.9442</td>\n",
              "      <td>0.7961</td>\n",
              "      <td>0.8610</td>\n",
              "      <td>0.8493</td>\n",
              "      <td>0.7262</td>\n",
              "      <td>0.7300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.8519</td>\n",
              "      <td>0.9200</td>\n",
              "      <td>0.7827</td>\n",
              "      <td>0.8549</td>\n",
              "      <td>0.8481</td>\n",
              "      <td>0.7209</td>\n",
              "      <td>0.7280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.8519</td>\n",
              "      <td>0.9254</td>\n",
              "      <td>0.8140</td>\n",
              "      <td>0.8542</td>\n",
              "      <td>0.8512</td>\n",
              "      <td>0.7293</td>\n",
              "      <td>0.7314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0.8704</td>\n",
              "      <td>0.9274</td>\n",
              "      <td>0.7798</td>\n",
              "      <td>0.8936</td>\n",
              "      <td>0.8642</td>\n",
              "      <td>0.7460</td>\n",
              "      <td>0.7710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Mean</th>\n",
              "      <td>0.8752</td>\n",
              "      <td>0.9500</td>\n",
              "      <td>0.8332</td>\n",
              "      <td>0.8813</td>\n",
              "      <td>0.8725</td>\n",
              "      <td>0.7686</td>\n",
              "      <td>0.7756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SD</th>\n",
              "      <td>0.0383</td>\n",
              "      <td>0.0224</td>\n",
              "      <td>0.0535</td>\n",
              "      <td>0.0398</td>\n",
              "      <td>0.0393</td>\n",
              "      <td>0.0707</td>\n",
              "      <td>0.0699</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC\n",
              "0       0.9636  0.9958  0.9674  0.9636  0.9636  0.9357  0.9357\n",
              "1       0.8909  0.9637  0.8826  0.8943  0.8918  0.8065  0.8069\n",
              "2       0.8182  0.9372  0.8250  0.8134  0.8144  0.6722  0.6740\n",
              "3       0.8545  0.9567  0.8264  0.8576  0.8511  0.7312  0.7382\n",
              "4       0.8909  0.9625  0.8083  0.9081  0.8863  0.7923  0.8098\n",
              "5       0.9074  0.9673  0.8499  0.9124  0.9054  0.8259  0.8306\n",
              "6       0.8519  0.9442  0.7961  0.8610  0.8493  0.7262  0.7300\n",
              "7       0.8519  0.9200  0.7827  0.8549  0.8481  0.7209  0.7280\n",
              "8       0.8519  0.9254  0.8140  0.8542  0.8512  0.7293  0.7314\n",
              "9       0.8704  0.9274  0.7798  0.8936  0.8642  0.7460  0.7710\n",
              "Mean    0.8752  0.9500  0.8332  0.8813  0.8725  0.7686  0.7756\n",
              "SD      0.0383  0.0224  0.0535  0.0398  0.0393  0.0707  0.0699"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WP1PAC6aVfQX"
      },
      "source": [
        "Por fim, podemos testar nosso modelo em funcionamento usando dados dos fundos em uma data que não tínhamos visto antes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvgBtB5xGoPB"
      },
      "source": [
        "df_teste = pd.read_csv('https://raw.githubusercontent.com/TailUFPB/fundos-imobiliarios/main/CSV_Antigos_PreProc/202010-ModeloML.csv')\n",
        "df_teste.drop(['Unnamed: 0','Setor', 'Preço Atual','Rentab.Período', 'DY Ano', 'Dividendo'], axis='columns', inplace=True)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8wMY7S2WUfD"
      },
      "source": [
        "Usando as notas obtidas no nosso rankeamento, vamos selecionar alguns fundos bons, médios e ruins, para vermos como nosso modelo os classifica:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJP9BvAVHdW3"
      },
      "source": [
        "#Fundos bons:\n",
        "df_irdm = df_teste[df_teste[\"Códigodo fundo\"] == 'IRDM11']\n",
        "df_bbpo = df_teste[df_teste[\"Códigodo fundo\"] == 'BBPO11']\n",
        "\n",
        "#Fundos médios:\n",
        "df_alzr = df_teste[df_teste[\"Códigodo fundo\"] == 'ALZR11']\n",
        "df_hgre = df_teste[df_teste[\"Códigodo fundo\"] == 'HGRE11']\n",
        "\n",
        "#Fundos ruins:\n",
        "df_xpht = df_teste[df_teste[\"Códigodo fundo\"] == 'XPHT11']\n",
        "df_edga = df_teste[df_teste[\"Códigodo fundo\"] == 'EDGA11']"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPmt21xsWzdE",
        "outputId": "23ca1d8b-479d-4e42-a28b-85a36509fa97"
      },
      "source": [
        "print('Fundo IRDM11: ',best_model.predict(df_irdm.iloc[:,1:]))\n",
        "print('Fundo BBPO11: ',best_model.predict(df_bbpo.iloc[:,1:]))\n",
        "print('Fundo ALZR11: ',best_model.predict(df_alzr.iloc[:,1:]))\n",
        "print('Fundo HGRE11: ',best_model.predict(df_hgre.iloc[:,1:]))\n",
        "print('Fundo XPHT11: ',best_model.predict(df_xpht.iloc[:,1:]))\n",
        "print('Fundo EDGA11: ',best_model.predict(df_edga.iloc[:,1:]))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fundo IRDM11:  [0]\n",
            "Fundo BBPO11:  [0]\n",
            "Fundo ALZR11:  [1]\n",
            "Fundo HGRE11:  [1]\n",
            "Fundo XPHT11:  [2]\n",
            "Fundo EDGA11:  [2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0fIP--ZXrnQ"
      },
      "source": [
        "Como a label 0 corresponde a bom, a label 1 corresponde a médio, e a label 2 corresponde a ruim, podemos ver que nosso modelo conseguiu classificar esses exemplos corretamente!"
      ]
    }
  ]
}